#!/usr/bin/env python3
"""
æŠ€æœ¯æ ‡å‡†æ–‡æ¡£è´¨é‡è‡ªåŠ¨æ£€æŸ¥è„šæœ¬
ç”¨æ³•: python3 check_standard.py <æ–‡ä»¶è·¯å¾„> [--type cn|int]
é…åˆ writing-projects/academic-writer-skill/SKILL.md Â§7.6 ä½¿ç”¨
"""
import re
import sys
import argparse

def load_document(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

# ============================================================
# é€šç”¨æ£€æŸ¥ï¼ˆå›½å†…/å›½é™…å…±ç”¨ï¼‰
# ============================================================

def check_structure_cn(content):
    """æ£€æŸ¥å›½å†…æ ‡å‡†ç»“æ„å®Œæ•´æ€§ (GB/T 1.1-2020)"""
    issues = []
    required = [
        ('å‰è¨€', r'å‰\s*è¨€'),
        ('èŒƒå›´', r'^1\s+èŒƒå›´|^1\s+Scope'),
        ('è§„èŒƒæ€§å¼•ç”¨æ–‡ä»¶', r'^2\s+è§„èŒƒæ€§å¼•ç”¨æ–‡ä»¶'),
        ('æœ¯è¯­å’Œå®šä¹‰', r'^3\s+æœ¯è¯­å’Œå®šä¹‰|^3\s+æœ¯è¯­'),
    ]
    for name, pattern in required:
        if not re.search(pattern, content, re.MULTILINE):
            issues.append({
                'level': 'SEVERE', 'category': 'ç»“æ„åˆè§„',
                'message': f'ç¼ºå°‘å¿…è¦ç« èŠ‚ï¼š{name}',
                'suggestion': f'æŒ‰GB/T 1.1-2020è¦æ±‚è¡¥å……"{name}"ç« èŠ‚'
            })
    
    # æ£€æŸ¥å‰è¨€è¦ç´ 
    foreword_match = re.search(r'å‰\s*è¨€(.*?)(?=^1\s|\Z)', content, re.DOTALL | re.MULTILINE)
    if foreword_match:
        fw = foreword_match.group(1)
        for element in ['å½’å£', 'èµ·è‰å•ä½', 'èµ·è‰äºº']:
            if element not in fw:
                issues.append({
                    'level': 'WARNING', 'category': 'å‰è¨€è¦ç´ ',
                    'message': f'å‰è¨€ä¸­æœªæ‰¾åˆ°"{element}"ä¿¡æ¯',
                    'suggestion': f'å‰è¨€é¡»åŒ…å«å½’å£å•ä½ã€èµ·è‰å•ä½ã€ä¸»è¦èµ·è‰äºº'
                })
    return issues

def check_structure_int(content):
    """æ£€æŸ¥å›½é™…æ ‡å‡†ç»“æ„å®Œæ•´æ€§ (ISO/IEC Directives Part 2)"""
    issues = []
    required = [
        ('Foreword', r'Foreword'),
        ('Scope', r'^1\s+Scope'),
        ('Normative references', r'^2\s+Normative references'),
        ('Terms and definitions', r'^3\s+Terms and definitions'),
    ]
    for name, pattern in required:
        if not re.search(pattern, content, re.MULTILINE):
            issues.append({
                'level': 'SEVERE', 'category': 'Structure',
                'message': f'Missing required clause: {name}',
                'suggestion': f'Add "{name}" per ISO/IEC Directives Part 2'
            })
    
    # æ£€æŸ¥æ³•æ–‡æ ‡é¢˜
    if not re.search(r'[Ã€-Ã¿]', content):
        issues.append({
            'level': 'WARNING', 'category': 'Bilingual title',
            'message': 'æœªæ£€æµ‹åˆ°æ³•æ–‡å­—ç¬¦â€”â€”ISOæ ‡å‡†é¡»æä¾›è‹±æ³•åŒè¯­æ ‡é¢˜',
            'suggestion': 'åœ¨å°é¢/æ ‡é¢˜é¡µæ·»åŠ æ³•æ–‡æ ‡é¢˜'
        })
    
    # æ£€æŸ¥é˜¶æ®µæ ‡è¯†
    stages = ['WD', 'CD', 'DIS', 'FDIS', 'IS']
    found_stage = any(re.search(rf'\b{s}\b', content[:500]) for s in stages)
    if not found_stage:
        issues.append({
            'level': 'CHECK', 'category': 'Stage',
            'message': 'æœªåœ¨æ–‡æ¡£å¼€å¤´æ£€æµ‹åˆ°é˜¶æ®µæ ‡è¯†(WD/CD/DIS/FDIS/IS)',
            'suggestion': 'ç¡®è®¤æ–‡ä»¶é˜¶æ®µå¹¶åœ¨å°é¢æ ‡æ³¨'
        })
    return issues

def check_normative_wording_cn(content):
    """æ£€æŸ¥å›½å†…æ ‡å‡†æ¡æ–‡ç”¨è¯­ä¸€è‡´æ€§"""
    issues = []
    # æ­£ç¡®ç”¨è¯­: åº”/å®œ/å¯/ä¸åº”/ä¸å®œ
    # é”™è¯¯ç”¨è¯­: å¿…é¡»/å»ºè®®/å¸Œæœ›/æœ€å¥½/å°½é‡
    
    wrong_words = {
        'å¿…é¡»': 'æ ‡å‡†æ¡æ–‡ä¸­åº”ä½¿ç”¨ã€Œåº”ã€è€Œéã€Œå¿…é¡»ã€',
        'å»ºè®®': 'æ ‡å‡†æ¡æ–‡ä¸­åº”ä½¿ç”¨ã€Œå®œã€è€Œéã€Œå»ºè®®ã€',
        'å¸Œæœ›': 'æ ‡å‡†æ¡æ–‡ä¸å®œä½¿ç”¨ã€Œå¸Œæœ›ã€',
        'æœ€å¥½': 'æ ‡å‡†æ¡æ–‡åº”ä½¿ç”¨ã€Œå®œã€è€Œéã€Œæœ€å¥½ã€',
        'å°½é‡': 'æ ‡å‡†æ¡æ–‡åº”ä½¿ç”¨ã€Œå®œã€è€Œéã€Œå°½é‡ã€',
        'éœ€è¦': 'æ¡æ–‡ä¸­è€ƒè™‘ä½¿ç”¨ã€Œåº”ã€(å¼ºåˆ¶)æˆ–ã€Œå®œã€(æ¨è)æ›¿ä»£ã€Œéœ€è¦ã€',
        'è¦æ±‚': 'æ¡æ–‡æ­£æ–‡ä¸­ã€Œè¦æ±‚ã€å¯èƒ½åº”æ”¹ä¸ºã€Œåº”ã€',
    }
    
    # è·³è¿‡å‰è¨€å’Œå¼•è¨€ï¼Œåªæ£€æŸ¥æ­£æ–‡æ¡æ–‡
    body_match = re.search(r'^1\s+èŒƒå›´', content, re.MULTILINE)
    if body_match:
        body = content[body_match.start():]
    else:
        body = content
    
    for word, suggestion in wrong_words.items():
        occurrences = [(m.start(), m.group()) for m in re.finditer(word, body)]
        if occurrences:
            # è¿‡æ»¤æ‰å¼•ç”¨/è„šæ³¨/æœ¯è¯­å®šä¹‰ä¸­çš„ä½¿ç”¨
            real_count = len(occurrences)
            if real_count > 0:
                issues.append({
                    'level': 'WARNING', 'category': 'æ¡æ–‡ç”¨è¯­',
                    'message': f'æ¡æ–‡æ­£æ–‡ä¸­å‡ºç°ã€Œ{word}ã€({real_count}å¤„)',
                    'suggestion': suggestion
                })
    
    # ç»Ÿè®¡æ­£ç¡®ç”¨è¯­åˆ†å¸ƒ
    correct_counts = {}
    for w in ['åº”', 'å®œ', 'å¯', 'ä¸åº”', 'ä¸å®œ']:
        # éœ€è¦ç²¾å‡†åŒ¹é…ï¼Œé¿å…"åº”ç”¨""åº”è¯¥"ç­‰è¯¯åŒ¹é…
        if w in ['åº”', 'å®œ', 'å¯']:
            # å‰åä¸èƒ½æ¥ä¸­æ–‡å­—
            pattern = rf'(?<![ä¸\u4e00-\u9fff]){w}(?![ç”¨è¯¥å½“ä¸ºä»¥è¡Œ])'
            if w == 'å¯':
                pattern = rf'(?<!ä¸)å¯(?![ä»¥èƒ½è¡Œæ˜¯ç”¨])'
        else:
            pattern = re.escape(w)
        count = len(re.findall(pattern, body))
        correct_counts[w] = count
    
    total_normative = sum(correct_counts.values())
    if total_normative == 0:
        issues.append({
            'level': 'SEVERE', 'category': 'æ¡æ–‡ç”¨è¯­',
            'message': 'æœªæ£€æµ‹åˆ°è§„èŒƒæ€§ç”¨è¯­ï¼ˆåº”/å®œ/å¯/ä¸åº”/ä¸å®œï¼‰',
            'suggestion': 'æ¡æ–‡æ­£æ–‡å¿…é¡»ä½¿ç”¨GB/T 1.1-2020è§„å®šçš„è§„èŒƒç”¨è¯­'
        })
    
    return issues, correct_counts

def check_normative_wording_int(content):
    """æ£€æŸ¥å›½é™…æ ‡å‡†æ¡æ–‡ç”¨è¯­ä¸€è‡´æ€§"""
    issues = []
    
    wrong_words = {
        'must': 'æ¡æ–‡ä¸­åº”ä½¿ç”¨ "shall" è€Œé "must"',
        'need to': 'æ¡æ–‡ä¸­åº”ä½¿ç”¨ "shall" æˆ– "should" è€Œé "need to"',
        'has to': 'æ¡æ–‡ä¸­åº”ä½¿ç”¨ "shall" è€Œé "has to"',
        'is required': 'æ¡æ–‡ä¸­åº”ä½¿ç”¨ "shall" è€Œé "is required"',
        'it is recommended': 'æ¡æ–‡ä¸­åº”ä½¿ç”¨ "should" è€Œé "it is recommended"',
    }
    
    body_match = re.search(r'^1\s+Scope', content, re.MULTILINE)
    body = content[body_match.start():] if body_match else content
    
    for word, suggestion in wrong_words.items():
        count = len(re.findall(rf'\b{word}\b', body, re.IGNORECASE))
        if count > 0:
            issues.append({
                'level': 'WARNING', 'category': 'Normative wording',
                'message': f'Found "{word}" in normative text ({count} times)',
                'suggestion': suggestion
            })
    
    correct_counts = {}
    for w in ['shall', 'should', 'may', 'shall not', 'should not']:
        count = len(re.findall(rf'\b{w}\b', body))
        correct_counts[w] = count
    
    total = sum(correct_counts.values())
    if total == 0:
        issues.append({
            'level': 'SEVERE', 'category': 'Normative wording',
            'message': 'No normative keywords (shall/should/may) detected',
            'suggestion': 'Normative text must use ISO/IEC Directives Part 2 wording'
        })
    
    return issues, correct_counts

def check_clause_numbering(content):
    """æ£€æŸ¥æ¡æ–‡ç¼–å·è¿ç»­æ€§"""
    issues = []
    clause_nums = re.findall(r'^(\d+(?:\.\d+)*)\s', content, re.MULTILINE)
    
    if not clause_nums:
        return issues
    
    # æ£€æŸ¥ä¸€çº§æ¡ç›®è¿ç»­æ€§
    top_level = sorted(set(int(n.split('.')[0]) for n in clause_nums if '.' not in n or n.count('.') == 0))
    
    for i in range(len(top_level) - 1):
        if top_level[i+1] - top_level[i] > 1:
            issues.append({
                'level': 'WARNING', 'category': 'æ¡æ–‡ç¼–å·',
                'message': f'ä¸€çº§æ¡æ–‡ç¼–å·ä¸è¿ç»­ï¼š{top_level[i]}åè·³è‡³{top_level[i+1]}',
                'suggestion': 'æ£€æŸ¥æ˜¯å¦é—æ¼ç« èŠ‚'
            })
    return issues

def check_cross_references(content):
    """æ£€æŸ¥äº¤å‰å¼•ç”¨æœ‰æ•ˆæ€§"""
    issues = []
    # æŸ¥æ‰¾äº¤å‰å¼•ç”¨
    refs = re.findall(r'è§?\s*(\d+\.\d+(?:\.\d+)?)', content)
    # æŸ¥æ‰¾å·²å®šä¹‰çš„æ¡ç›®
    defined = set(re.findall(r'^(\d+(?:\.\d+)*)\s', content, re.MULTILINE))
    
    for ref in refs:
        if ref not in defined:
            issues.append({
                'level': 'CHECK', 'category': 'äº¤å‰å¼•ç”¨',
                'message': f'å¼•ç”¨äº†æ¡æ–‡ {ref}ï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”ç« èŠ‚',
                'suggestion': f'ç¡®è®¤ {ref} æ˜¯å¦å­˜åœ¨ï¼Œæˆ–è°ƒæ•´å¼•ç”¨'
            })
    return issues

def check_annex_labels(content):
    """æ£€æŸ¥é™„å½•æ ‡æ³¨"""
    issues = []
    annexes = re.findall(r'é™„å½•\s*([A-Z])\s*(.*)', content)
    for letter, rest in annexes:
        if 'è§„èŒƒæ€§' not in rest and 'èµ„æ–™æ€§' not in rest and 'normative' not in rest.lower() and 'informative' not in rest.lower():
            issues.append({
                'level': 'WARNING', 'category': 'é™„å½•æ ‡æ³¨',
                'message': f'é™„å½•{letter}æœªæ ‡æ³¨ç±»å‹',
                'suggestion': f'é¡»æ ‡æ³¨"(è§„èŒƒæ€§)"æˆ–"(èµ„æ–™æ€§)"'
            })
    return issues

def check_units(content, is_international=False):
    """æ£€æŸ¥é‡å’Œå•ä½"""
    issues = []
    # å¸¸è§éSIå•ä½
    non_si = {
        r'\bpsi\b': 'Pa (å¸•æ–¯å¡)',
        r'\bft\b': 'm (ç±³)',
        r'\bgal\b': 'L (å‡)',
        r'\binch\b': 'mm (æ¯«ç±³)',
    }
    for pattern, replacement in non_si.items():
        if re.search(pattern, content, re.IGNORECASE):
            issues.append({
                'level': 'CHECK', 'category': 'é‡å’Œå•ä½',
                'message': f'æ£€æµ‹åˆ°å¯èƒ½çš„éSIå•ä½åŒ¹é…',
                'suggestion': f'è¯·ç¡®è®¤æ˜¯å¦åº”ä½¿ç”¨SIå•ä½ {replacement}'
            })
    return issues

def check_terminology_definitions(content):
    """æ£€æŸ¥æœ¯è¯­å®šä¹‰æ ¼å¼"""
    issues = []
    # æ£€æŸ¥æœ¯è¯­ç« èŠ‚
    term_section = re.search(r'(æœ¯è¯­å’Œå®šä¹‰|Terms and definitions)(.*?)(?=^\d+\s+(?!æœ¯è¯­)|\Z)', 
                             content, re.DOTALL | re.MULTILINE)
    if term_section:
        terms_text = term_section.group(2)
        term_entries = re.findall(r'^3\.\d+\s*\n?(.*?)(?=^3\.\d+|\Z)', terms_text, re.DOTALL | re.MULTILINE)
        if len(term_entries) == 0:
            issues.append({
                'level': 'WARNING', 'category': 'æœ¯è¯­å®šä¹‰',
                'message': 'æœ¯è¯­ç« èŠ‚ä¸ºç©ºæˆ–æ ¼å¼ä¸è§„èŒƒ',
                'suggestion': 'æ¯ä¸ªæœ¯è¯­ä½¿ç”¨"å±æ¦‚å¿µ+ç§å·®"å®šä¹‰æ³•'
            })
    return issues

def generate_stats(content, std_type):
    """ç”Ÿæˆæ–‡æ¡£ç»Ÿè®¡"""
    char_count = len(content)
    lines = content.split('\n')
    clause_count = len(re.findall(r'^\d+(?:\.\d+)*\s', content, re.MULTILINE))
    annex_count = len(re.findall(r'é™„å½•\s*[A-Z]|Annex\s+[A-Z]', content))
    
    return {
        'æ ‡å‡†ç±»å‹': 'å›½å†…æ ‡å‡†' if std_type == 'cn' else 'å›½é™…æ ‡å‡†',
        'æ€»å­—ç¬¦æ•°': char_count,
        'æ€»è¡Œæ•°': len(lines),
        'æ¡æ–‡æ•°': clause_count,
        'é™„å½•æ•°': annex_count,
    }

def run_checks(filepath, std_type='cn'):
    """æ‰§è¡Œå…¨éƒ¨æ£€æŸ¥"""
    content = load_document(filepath)
    all_issues = []
    
    # ç»“æ„æ£€æŸ¥
    if std_type == 'cn':
        all_issues.extend(check_structure_cn(content))
    else:
        all_issues.extend(check_structure_int(content))
    
    # æ¡æ–‡ç”¨è¯­æ£€æŸ¥
    if std_type == 'cn':
        wording_issues, wording_stats = check_normative_wording_cn(content)
    else:
        wording_issues, wording_stats = check_normative_wording_int(content)
    all_issues.extend(wording_issues)
    
    # é€šç”¨æ£€æŸ¥
    all_issues.extend(check_clause_numbering(content))
    all_issues.extend(check_cross_references(content))
    all_issues.extend(check_annex_labels(content))
    all_issues.extend(check_units(content, std_type == 'int'))
    all_issues.extend(check_terminology_definitions(content))
    
    stats = generate_stats(content, std_type)
    
    # è¾“å‡ºæŠ¥å‘Š
    print(f"\n{'='*65}")
    if std_type == 'cn':
        print(f" ğŸ“‹ å›½å†…æŠ€æœ¯æ ‡å‡†è´¨é‡æ£€æŸ¥æŠ¥å‘Š (GB/T 1.1-2020)")
    else:
        print(f" ğŸ“‹ International Standard Quality Check (ISO/IEC Directives Part 2)")
    print(f"{'='*65}")
    
    print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    for k, v in stats.items():
        print(f"   {k}: {v}")
    
    print(f"\nğŸ“Š è§„èŒƒç”¨è¯­åˆ†å¸ƒ:")
    for w, c in wording_stats.items():
        bar = 'â–ˆ' * min(c, 40)
        print(f"   ã€Œ{w}ã€: {c}æ¬¡ {bar}")
    
    # è®¡ç®—åˆè§„ç‡
    severe = [i for i in all_issues if i['level'] == 'SEVERE']
    warning = [i for i in all_issues if i['level'] == 'WARNING']
    check = [i for i in all_issues if i['level'] == 'CHECK']
    
    total_checks = 10  # åŸºå‡†æ£€æŸ¥é¡¹æ•°
    compliance_rate = max(0, (total_checks - len(severe)) / total_checks * 100)
    
    print(f"\nğŸ“Š æ¡æ–‡åˆè§„ç‡: {compliance_rate:.0f}%")
    print(f"   å…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜ "
          f"(ğŸ”´ä¸¥é‡:{len(severe)} ğŸŸ¡è­¦å‘Š:{len(warning)} âšªå¾…ç¡®è®¤:{len(check)})")
    
    if severe:
        print(f"\nğŸ”´ ä¸¥é‡é—®é¢˜ï¼ˆå¿…é¡»ä¿®æ­£ï¼‰:")
        print(f"{'â€”'*55}")
        for i, item in enumerate(severe, 1):
            print(f"  {i}. [{item['category']}] {item['message']}")
            print(f"     â†’ {item['suggestion']}")
    
    if warning:
        print(f"\nğŸŸ¡ è­¦å‘Šï¼ˆå»ºè®®ä¿®æ­£ï¼‰:")
        print(f"{'â€”'*55}")
        for i, item in enumerate(warning, 1):
            print(f"  {i}. [{item['category']}] {item['message']}")
            print(f"     â†’ {item['suggestion']}")
    
    if check:
        print(f"\nâšª éœ€äººå·¥ç¡®è®¤:")
        print(f"{'â€”'*55}")
        for i, item in enumerate(check, 1):
            print(f"  {i}. [{item['category']}] {item['message']}")
            print(f"     â†’ {item['suggestion']}")
    
    print(f"\n{'='*65}")
    if severe:
        print("âŒ æ¡æ–‡åˆè§„ç‡æœªè¾¾100%ï¼Œé¡»ä¿®æ­£åé‡æ£€ã€‚")
    elif warning:
        print("âš ï¸  å»ºè®®ä¿®æ­£è­¦å‘Šé¡¹åæäº¤å®¡æŸ¥ã€‚")
    else:
        print("âœ… æ ‡å‡†æ–‡æ¡£æ£€æŸ¥é€šè¿‡ï¼Œå¯æäº¤å®¡æŸ¥ã€‚")
    print()
    
    return len(severe) == 0

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='æŠ€æœ¯æ ‡å‡†æ–‡æ¡£è´¨é‡æ£€æŸ¥')
    parser.add_argument('filepath', help='æ ‡å‡†æ–‡æ¡£æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--type', choices=['cn', 'int'], default='cn',
                       help='æ ‡å‡†ç±»å‹: cn=å›½å†…(GB/T 1.1), int=å›½é™…(ISO/IEC)')
    args = parser.parse_args()
    
    passed = run_checks(args.filepath, args.type)
    sys.exit(0 if passed else 1)
