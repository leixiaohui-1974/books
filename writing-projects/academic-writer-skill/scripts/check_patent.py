#!/usr/bin/env python3
"""check_patent.py â€” å‘æ˜ä¸“åˆ©ç”³è¯·æ–‡ä»¶è‡ªåŠ¨è´¨é‡æ£€æŸ¥

Usage:
    python3 check_patent.py patent.md

æ£€æŸ¥é¡¹ï¼ˆ12é¡¹ï¼‰:
  1. æ–‡ä»¶ç»“æ„å®Œæ•´æ€§ï¼ˆæ ‡é¢˜â†’æŠ€æœ¯é¢†åŸŸâ†’èƒŒæ™¯â†’å‘æ˜å†…å®¹â†’å®æ–½æ–¹å¼â†’æƒåˆ©è¦æ±‚â†’æ‘˜è¦ï¼‰
  2. æƒåˆ©è¦æ±‚ä¹¦è§„èŒƒï¼ˆç‹¬æƒ/ä»å±/å±‚æ¬¡/å›æŒ‡ç”¨è¯­ï¼‰
  3. ç‹¬ç«‹æƒåˆ©è¦æ±‚ä¿æŠ¤èŒƒå›´è¯„ä¼°
  4. è¯´æ˜ä¹¦-æƒåˆ©è¦æ±‚ä¸€è‡´æ€§
  5. èƒŒæ™¯æŠ€æœ¯å¼•ç”¨ï¼ˆâ‰¥3ç¯‡å¯¹æ¯”æ–‡ä»¶+ç¼ºé™·åˆ†æï¼‰
  6. æœ‰ç›Šæ•ˆæœé‡åŒ–ç¨‹åº¦
  7. å®æ–½ä¾‹å‚æ•°å…·ä½“åŒ–
  8. å›æŒ‡ç”¨è¯­ç»Ÿä¸€æ€§ï¼ˆ"æ‰€è¿°"ï¼‰
  9. å•ä¸€æ€§æ£€æŸ¥
  10. æ‘˜è¦è´¨é‡ï¼ˆ300å­—ä»¥å†…+é™„å›¾è¯´æ˜ï¼‰
  11. é™„å›¾å®Œæ•´æ€§
  12. æŠ€æœ¯æœ¯è¯­ä¸€è‡´æ€§
"""

import re
import sys
import os


def check_structure(text):
    """æ£€æŸ¥ä¸“åˆ©æ–‡ä»¶ç»“æ„å®Œæ•´æ€§ã€‚"""
    required = {
        'å‘æ˜åç§°': r'(?:å‘æ˜åç§°|ä¸€ç§)',
        'æŠ€æœ¯é¢†åŸŸ': r'æŠ€æœ¯é¢†åŸŸ',
        'èƒŒæ™¯æŠ€æœ¯': r'èƒŒæ™¯æŠ€æœ¯',
        'å‘æ˜å†…å®¹': r'å‘æ˜å†…å®¹',
        'æŠ€æœ¯é—®é¢˜': r'æŠ€æœ¯é—®é¢˜|ç›®çš„åœ¨äº|ä¸ºäº†è§£å†³',
        'æŠ€æœ¯æ–¹æ¡ˆ': r'æŠ€æœ¯æ–¹æ¡ˆ|ä¸ºå®ç°ä¸Šè¿°ç›®çš„|ä¸ºè¾¾åˆ°ä¸Šè¿°ç›®çš„',
        'æœ‰ç›Šæ•ˆæœ': r'æœ‰ç›Šæ•ˆæœ',
        'é™„å›¾è¯´æ˜': r'é™„å›¾è¯´æ˜|é™„å›¾',
        'å…·ä½“å®æ–½æ–¹å¼': r'å…·ä½“å®æ–½æ–¹å¼|å®æ–½ä¾‹',
        'æƒåˆ©è¦æ±‚ä¹¦': r'æƒåˆ©è¦æ±‚ä¹¦|æƒåˆ©è¦æ±‚',
        'è¯´æ˜ä¹¦æ‘˜è¦': r'æ‘˜è¦|è¯´æ˜ä¹¦æ‘˜è¦',
    }
    found = {}
    missing = []
    for name, pattern in required.items():
        if re.search(pattern, text):
            found[name] = True
        else:
            missing.append(name)
    return found, missing


def check_claims(text):
    """æ£€æŸ¥æƒåˆ©è¦æ±‚ä¹¦è§„èŒƒã€‚"""
    issues = []

    # Extract claims section
    m = re.search(r'æƒåˆ©è¦æ±‚[ä¹¦\s]*\n(.*?)(?=è¯´æ˜ä¹¦æ‘˜è¦|æ‘˜è¦|\Z)', text, re.S)
    if not m:
        return ['æœªæ‰¾åˆ°æƒåˆ©è¦æ±‚ä¹¦'], 0, 0

    claims_text = m.group(1)
    claims = re.findall(r'(\d+)[ã€.ï¼]\s*(.*?)(?=\n\d+[ã€.ï¼]|\Z)', claims_text, re.S)

    if not claims:
        return ['æƒåˆ©è¦æ±‚ä¹¦ä¸ºç©ºæˆ–æ ¼å¼æ— æ³•è§£æ'], 0, 0

    total_claims = len(claims)
    independent = 0
    dependent = 0

    for num, content in claims:
        content = content.strip()
        # Check if independent or dependent
        if re.search(r'æ ¹æ®æƒåˆ©è¦æ±‚\d+|å¦‚æƒåˆ©è¦æ±‚\d+', content):
            dependent += 1
        else:
            independent += 1

        # Check "æ‰€è¿°" usage
        if 'è¯¥' in content and 'æ‰€è¿°' not in content:
            issues.append(f'æƒåˆ©è¦æ±‚{num}: ä½¿ç”¨"è¯¥"è€Œé"æ‰€è¿°"å›æŒ‡')

        # Check for vague terms
        vague = re.findall(r'(åˆé€‚çš„|é€‚å½“çš„|ä¸€å®šçš„|å¤§çº¦|è‹¥å¹²)', content)
        if vague:
            issues.append(f'æƒåˆ©è¦æ±‚{num}: å«æ¨¡ç³Šç”¨è¯­ã€Œ{"ã€".join(vague)}ã€')

    if independent == 0:
        issues.append('æœªæ£€æµ‹åˆ°ç‹¬ç«‹æƒåˆ©è¦æ±‚')
    if total_claims < 5:
        issues.append(f'æƒåˆ©è¦æ±‚ä»…{total_claims}æ¡(å»ºè®®â‰¥8æ¡)')
    if dependent > 0 and dependent < independent * 2:
        issues.append(f'ä»å±æƒåˆ©è¦æ±‚{dependent}æ¡åå°‘(å»ºè®®æ¯ä¸ªç‹¬æƒæœ‰â‰¥2æ¡ä»å±)')

    return issues, independent, dependent


def check_independent_claim(text):
    """è¯„ä¼°ç‹¬ç«‹æƒåˆ©è¦æ±‚ä¿æŠ¤èŒƒå›´ã€‚"""
    issues = []

    m = re.search(r'æƒåˆ©è¦æ±‚[ä¹¦\s]*\n\s*1[ã€.ï¼]\s*(.*?)(?=\n\d+[ã€.ï¼]|\Z)', text, re.S)
    if not m:
        return ['æœªæ‰¾åˆ°ç¬¬ä¸€æ¡ç‹¬ç«‹æƒåˆ©è¦æ±‚']

    claim1 = m.group(1).strip()

    # Count limiting features
    steps = re.findall(r'æ­¥éª¤[A-Z\d]|[ï¼ˆ(][A-Za-z\d][ï¼‰)]|S\d+', claim1)
    features = len(re.findall(r'[ï¼›;ã€‚]', claim1)) + 1

    if features > 10:
        issues.append(f'ç‹¬æƒé™å®šç‰¹å¾è¿‡å¤š({features}ä¸ª, ä¿æŠ¤èŒƒå›´å¯èƒ½è¿‡çª„)')
    if len(claim1) > 800:
        issues.append(f'ç‹¬æƒæ–‡å­—è¿‡é•¿({len(claim1)}å­—, å»ºè®®ç²¾ç®€)')
    if len(claim1) < 100:
        issues.append(f'ç‹¬æƒæ–‡å­—è¿‡çŸ­({len(claim1)}å­—, å¯èƒ½é—æ¼å¿…è¦æŠ€æœ¯ç‰¹å¾)')

    # Check for "å…¶ç‰¹å¾åœ¨äº"
    if 'å…¶ç‰¹å¾åœ¨äº' not in claim1:
        issues.append('ç‹¬æƒç¼ºå°‘"å…¶ç‰¹å¾åœ¨äº"åˆ†ç•Œè¯­')

    return issues


def check_background(text):
    """æ£€æŸ¥èƒŒæ™¯æŠ€æœ¯å¼•ç”¨ã€‚"""
    issues = []

    m = re.search(r'èƒŒæ™¯æŠ€æœ¯\s*\n(.*?)(?=å‘æ˜å†…å®¹)', text, re.S)
    if not m:
        return ['æœªæ‰¾åˆ°èƒŒæ™¯æŠ€æœ¯éƒ¨åˆ†']

    bg = m.group(1)

    # Check for prior art references
    patent_refs = re.findall(r'CN\d{9}[AB]?|US\d{7,}|EP\d{7}', bg)
    lit_refs = re.findall(r'ã€Š[^ã€‹]+ã€‹|\[\d+\]', bg)
    total_refs = len(patent_refs) + len(lit_refs)

    if total_refs < 3:
        issues.append(f'èƒŒæ™¯æŠ€æœ¯å¼•ç”¨{total_refs}ç¯‡å¯¹æ¯”æ–‡ä»¶(å»ºè®®â‰¥3ç¯‡)')

    # Check for deficiency analysis
    deficiency_words = re.findall(r'ä¸è¶³|ç¼ºé™·|é—®é¢˜|å±€é™|æ— æ³•|éš¾ä»¥|æœªèƒ½', bg)
    if len(deficiency_words) < 2:
        issues.append('èƒŒæ™¯æŠ€æœ¯ç¼ºå°‘ç°æœ‰æŠ€æœ¯ç¼ºé™·åˆ†æ')

    return issues


def check_beneficial_effects(text):
    """æ£€æŸ¥æœ‰ç›Šæ•ˆæœé‡åŒ–ç¨‹åº¦ã€‚"""
    issues = []

    m = re.search(r'æœ‰ç›Šæ•ˆæœ\s*[ï¼š:]\s*(.*?)(?=é™„å›¾è¯´æ˜|å…·ä½“å®æ–½|æƒåˆ©è¦æ±‚|\n#)', text, re.S)
    if not m:
        return ['æœªæ‰¾åˆ°æœ‰ç›Šæ•ˆæœéƒ¨åˆ†']

    effects = m.group(1)
    numbers = re.findall(r'\d+\.?\d*\s*%|\d+\.?\d*\s*(?:å€|cm|m|s|å°æ—¶)', effects)
    if len(numbers) < 2:
        issues.append(f'æœ‰ç›Šæ•ˆæœé‡åŒ–æŒ‡æ ‡ä¸è¶³({len(numbers)}ä¸ª, å»ºè®®â‰¥3ä¸ª)')

    # Check for numbered effects
    effect_count = len(re.findall(r'[ï¼ˆ(]\d[ï¼‰)]|[\dâ‘ â‘¡â‘¢â‘£â‘¤]', effects))
    if effect_count < 2:
        issues.append('æœ‰ç›Šæ•ˆæœå»ºè®®åˆ†ç‚¹åˆ—ä¸¾(â‰¥3ä¸ªæ•ˆæœ)')

    return issues


def check_embodiment(text):
    """æ£€æŸ¥å®æ–½ä¾‹å‚æ•°å…·ä½“åŒ–ã€‚"""
    issues = []

    m = re.search(r'å…·ä½“å®æ–½æ–¹å¼\s*\n(.*?)(?=æƒåˆ©è¦æ±‚|\Z)', text, re.S)
    if not m:
        return ['æœªæ‰¾åˆ°å…·ä½“å®æ–½æ–¹å¼']

    impl = m.group(1)

    # Check for concrete parameters
    params = re.findall(r'\d+\.?\d*\s*(?:m|cm|mm|s|min|h|Hz|kHz|%|â„ƒ|Â°|æ­¥|å±‚|ä¸ª|ç»„)', impl)
    if len(params) < 10:
        issues.append(f'å®æ–½ä¾‹å‚æ•°ä¸å¤Ÿå…·ä½“(æ£€æµ‹åˆ°{len(params)}ä¸ªé‡åŒ–å‚æ•°, å»ºè®®â‰¥15ä¸ª)')

    # Check for vague implementations
    vague = re.findall(r'åˆé€‚çš„å‚æ•°|é€‚å½“çš„.*å€¼|æ ¹æ®éœ€è¦|è§†æƒ…å†µ', impl)
    if vague:
        issues.append(f'å®æ–½ä¾‹å«{len(vague)}å¤„æ¨¡ç³Šè¡¨è¿°(å¦‚"{vague[0]}")')

    return issues


def check_referencing_terms(text):
    """æ£€æŸ¥å›æŒ‡ç”¨è¯­ç»Ÿä¸€æ€§ã€‚"""
    issues = []

    # In claims, "æ‰€è¿°" is the correct referencing term
    m = re.search(r'æƒåˆ©è¦æ±‚[ä¹¦\s]*\n(.*?)(?=è¯´æ˜ä¹¦æ‘˜è¦|æ‘˜è¦|\Z)', text, re.S)
    if m:
        claims = m.group(1)
        bad_refs = len(re.findall(r'(?<!æ‰€)è¯¥(?!æ–¹æ³•|ç³»ç»Ÿ|è£…ç½®)', claims))
        suo_refs = len(re.findall(r'æ‰€è¿°', claims))
        if bad_refs > 0 and bad_refs > suo_refs * 0.3:
            issues.append(f'æƒåˆ©è¦æ±‚ä¸­"è¯¥"({bad_refs}å¤„)åº”ç»Ÿä¸€æ›¿æ¢ä¸º"æ‰€è¿°"')

    return issues


def check_abstract_quality(text):
    """æ£€æŸ¥æ‘˜è¦è´¨é‡ã€‚"""
    issues = []

    m = re.search(r'(?:è¯´æ˜ä¹¦)?æ‘˜è¦\s*[ï¼š:\n]\s*(.*?)(?=æ‘˜è¦é™„å›¾|\Z)', text, re.S)
    if not m:
        return ['æœªæ‰¾åˆ°æ‘˜è¦']

    abstract = m.group(1).strip()
    if len(abstract) > 300:
        issues.append(f'æ‘˜è¦{len(abstract)}å­—(ä¸Šé™300å­—)')
    if len(abstract) < 50:
        issues.append(f'æ‘˜è¦è¿‡çŸ­({len(abstract)}å­—)')

    return issues


def check_terminology_consistency(text):
    """æ£€æŸ¥æŠ€æœ¯æœ¯è¯­ä¸€è‡´æ€§ã€‚"""
    issues = []

    # Find terms that appear in multiple variants
    variant_groups = [
        (r'æ°´ç³»ç»Ÿæ§åˆ¶è®º|æ°´ç³»ç»Ÿè¿è¡Œå­¦|CHS', 'CHSç›¸å…³æœ¯è¯­'),
        (r'HydroOS|æ°´ç½‘æ“ä½œç³»ç»Ÿ|æ°´ç½‘OS', 'HydroOSç›¸å…³æœ¯è¯­'),
        (r'WSAL|WNAL|è‡ªä¸»è¿è¡Œç­‰çº§|è‡ªåŠ¨åŒ–ç­‰çº§', 'WSALç›¸å…³æœ¯è¯­'),
        (r'æ¨¡å‹é¢„æµ‹æ§åˆ¶|MPC|é¢„æµ‹æ§åˆ¶', 'MPCç›¸å…³æœ¯è¯­'),
    ]

    for pattern, group_name in variant_groups:
        variants = set()
        for m in re.finditer(pattern, text):
            variants.add(m.group())
        if len(variants) > 2:
            issues.append(f'{group_name}è¡¨è¿°ä¸ç»Ÿä¸€: {", ".join(variants)}')

    return issues


def main():
    if len(sys.argv) < 2:
        print("Usage: python3 check_patent.py <patent_file.md>")
        sys.exit(1)

    filepath = sys.argv[1]
    with open(filepath, encoding='utf-8') as f:
        text = f.read()

    print(f"{'â•' * 60}")
    print(f"  å‘æ˜ä¸“åˆ©ç”³è¯·æ–‡ä»¶è´¨é‡æ£€æŸ¥")
    print(f"  æ–‡ä»¶: {os.path.basename(filepath)} ({len(text):,}å­—)")
    print(f"{'â•' * 60}")

    total_issues = 0

    # 1. Structure
    found, missing = check_structure(text)
    status = 'âœ…' if not missing else 'âŒ'
    print(f"\n{status} 1. ç»“æ„å®Œæ•´æ€§: {len(found)}/{len(found)+len(missing)}é¡¹")
    for m in missing:
        print(f"     Â· ç¼ºå°‘: {m}")
        total_issues += 1

    # 2. Claims
    claim_issues, indep, dep = check_claims(text)
    status = 'âœ…' if not claim_issues else 'âŒ'
    print(f"\n{status} 2. æƒåˆ©è¦æ±‚ä¹¦: ç‹¬æƒ{indep}æ¡ ä»å±{dep}æ¡")
    for i in claim_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 3. Independent claim
    indep_issues = check_independent_claim(text)
    status = 'âœ…' if not indep_issues else 'ğŸŸ¡'
    print(f"\n{status} 3. ç‹¬æƒä¿æŠ¤èŒƒå›´")
    for i in indep_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 4. Background
    bg_issues = check_background(text)
    status = 'âœ…' if not bg_issues else 'ğŸŸ¡'
    print(f"\n{status} 4. èƒŒæ™¯æŠ€æœ¯")
    for i in bg_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 5. Effects
    eff_issues = check_beneficial_effects(text)
    status = 'âœ…' if not eff_issues else 'ğŸŸ¡'
    print(f"\n{status} 5. æœ‰ç›Šæ•ˆæœ")
    for i in eff_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 6. Embodiment
    emb_issues = check_embodiment(text)
    status = 'âœ…' if not emb_issues else 'ğŸŸ¡'
    print(f"\n{status} 6. å®æ–½ä¾‹")
    for i in emb_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 7. Referencing
    ref_issues = check_referencing_terms(text)
    status = 'âœ…' if not ref_issues else 'ğŸŸ¡'
    print(f"\n{status} 7. å›æŒ‡ç”¨è¯­")
    for i in ref_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 8. Abstract
    abs_issues = check_abstract_quality(text)
    status = 'âœ…' if not abs_issues else 'ğŸŸ¡'
    print(f"\n{status} 8. æ‘˜è¦")
    for i in abs_issues:
        print(f"     Â· {i}")
        total_issues += 1

    # 9. Terminology
    term_issues = check_terminology_consistency(text)
    status = 'âœ…' if not term_issues else 'ğŸŸ¡'
    print(f"\n{status} 9. æœ¯è¯­ä¸€è‡´æ€§")
    for i in term_issues:
        print(f"     Â· {i}")
        total_issues += 1

    score = max(0, 10 - total_issues * 0.6)
    print(f"\n{'â•' * 60}")
    print(f"  æ£€æµ‹åˆ° {total_issues} ä¸ªé—®é¢˜")
    print(f"  è´¨é‡è¯„ä¼°: {score:.1f}/10 (æˆæƒå‰æ™¯: {'è‰¯å¥½' if score >= 7.5 else 'éœ€æ”¹è¿›'})")
    print(f"{'â•' * 60}")


if __name__ == '__main__':
    main()
