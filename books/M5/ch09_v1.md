<!-- 变更日志
v1 2026-02-19: 初稿
-->

# 第九章 工程案例：瀚铎水网大模型实践

---

## 学习目标

完成本章后，读者应能够：

1. 描述瀚铎水网大模型（HanDuo Water Network Large Model）的系统总体架构，理解从数据层到服务层的五层设计逻辑及各层之间的接口关系；
2. 根据水利业务需求设计领域大语言模型的需求分析框架，建立功能需求、性能指标与用户场景之间的映射；
3. 复述水利知识体系构建的完整实践流程，包括知识图谱构建、领域语料库建设和知识质量保证方法；
4. 设计并实施大语言模型的领域适配训练方案，包括基座选型、继续预训练、指令微调和偏好优化的全流程；
5. 搭建面向水利场景的检索增强生成系统，处理分块策略选择、混合检索引擎配置和查询改写优化等工程问题；
6. 规划认知AI引擎与物理AI引擎的融合方案，设计双引擎接口和冲突消解机制的工程实现；
7. 制定领域大模型的测试评估方案和渐进式部署策略，建立运行监控与持续学习的反馈闭环。

---

## 9.1 项目背景与需求分析

### 9.1.1 瀚铎水网大模型的缘起

前八章系统阐述了水利认知智能的理论基础和关键技术。本章将这些理论和技术汇聚到一个完整的工程实践中——瀚铎水网大模型（HanDuo Water Network Large Model）的设计、开发与部署。

"瀚铎"之名取自"瀚海铎音"——"瀚海"寓意水网之广阔，"铎"是古代宣布政令时使用的铃铛，引申为水网调度的"智慧之声"。这个命名本身就反映了项目的定位：不是一个通用的人工智能系统，而是专为水网运行而生的领域认知智能平台。

瀚铎水网大模型项目的启动源于三方面的驱动力。

第一是业务驱动。随着中国南水北调、引江济淮、胶东调水等大型调水工程陆续投入运行，水网系统的规模和复杂度急剧增长。以某省级调水系统为例，日常运行需要管理超过200座闸站、3000余个监测点、数百项调度规程和数千页技术文档。调度员面临的信息过载问题日益严重：一个简单的流量调整决策可能需要查阅5份以上的规程文件、核对20个以上的监测点数据、评估10个以上的约束条件。在复杂工况下（如冰期、汛期叠加检修），决策所需的认知负荷远超单个调度员的承受能力。

第二是技术驱动。2023年以来，大语言模型技术的快速发展为解决上述问题提供了新的可能。通用大模型在自然语言理解、知识推理和代码生成方面展现了惊人的能力，但在水利等专业领域的表现仍然不尽如人意。第四章的分析表明，通用模型在水利术语识别、规程理解和工况推理方面存在系统性不足。这种差距恰恰指明了领域大模型的建设方向。

第三是体系驱动。在水系统控制论（Cybernetics of Hydro Systems, CHS）的框架中，认知AI引擎是实现水网自主运行不可或缺的组成部分（参见第一章图1-2的CHS体系坐标）。瀚铎水网大模型正是认知AI引擎的核心实现，它需要与物理AI引擎（基于水力学模型的仿真与优化系统）协同工作，在HydroOS水网操作系统的统一框架下为调度决策提供认知层面的支持。没有认知AI引擎的参与，水网自主等级将停留在L2（条件自主）以下，无法实现L3（有条件的高度自主）及以上的目标。

项目于2024年3月正式立项，经过需求分析（3个月）、系统设计（2个月）、迭代开发（10个月）和试运行（3个月）四个阶段，于2025年6月在首个示范工程——胶东调水工程——完成部署并投入试运行。截至本书撰写时（2026年初），系统已稳定运行超过8个月，日均处理调度员查询约180次，累积服务超过40,000次交互。

### 9.1.2 需求定义与功能规划

项目启动后的第一项重要工作是需求定义。项目组采用"角色-场景-功能"三层需求框架：首先识别系统的主要用户角色，然后分析每个角色的典型使用场景，最后从场景中提炼出具体的功能需求。

**用户角色分析**

瀚铎水网大模型的核心用户群体包括四类角色：

值班调度员是系统的主要日常用户。他们需要在值班期间实时监控水网运行状态，处理各类正常和异常工况。调度员的核心需求是快速获取与当前工况相关的信息、得到决策建议、并在执行操作前验证方案的安全性。调度员的专业背景差异较大——资深调度员具有十年以上的经验，对工程特性和规程细节了若指掌；而新入职的调度员可能仅有基本的水利知识，需要系统提供更详细的解释和指导。

调度管理人员关注的是系统运行的整体态势和趋势分析。他们需要了解一段时间内的运行绩效（如供水保障率、水质达标率、能耗指标等），识别潜在的运行风险，并为中长期调度计划的制定提供数据支撑。

运行维护工程师关注设备和系统的健康状态。他们需要了解设备的故障历史、维护记录和运行参数趋势，以便安排预防性维护和故障排查。

系统管理员负责知识库的更新维护和系统配置管理。当新的调度规程发布、工程参数变更或历史事件需要归档时，系统管理员需要便捷的工具来更新系统的知识基础。

**典型使用场景**

基于对上述四类用户的深入访谈和现场观察（项目组在三个调度中心累计驻场观察超过200小时），项目组梳理出28个典型使用场景，归纳为五大类：

第一类是规程查询与解释。调度员在执行操作时经常需要查阅调度规程中的具体条款，但规程文件通常长达数百页，条款之间存在复杂的交叉引用关系。例如，"汛期3号闸门的最大开度限制是多少"这个看似简单的问题，答案可能取决于上游来水量、下游水位、并行运行的闸门状态等多个条件，分散在规程的不同章节中。系统需要能够理解问题的具体工况背景，检索并综合相关条款，给出准确且完整的回答。

第二类是工况分析与决策建议。当水网运行状态发生变化时——无论是计划内的调整还是突发事件——调度员需要快速评估影响范围并制定应对方案。例如，"上游水库提前泄洪，预计2小时后干渠来水量增加40%，请分析影响并给出建议"。系统需要综合当前运行状态、水力传播特性和历史相似案例，给出分阶段的应对建议。

第三类是异常诊断与处置指导。当SCADA系统发出告警时，调度员需要判断告警的性质（真实异常还是传感器故障）、评估风险等级并执行相应的处置流程。系统需要结合告警数据、历史模式和设备状态，协助调度员快速定位问题根源并提供处置方案。

第四类是历史案例检索与类比分析。在处理复杂工况时，调度员常常需要参考历史上类似事件的处理经验。系统需要能够根据当前工况的特征，从历史事件库中检索出相似度最高的案例，并分析当前工况与历史案例的异同，提炼可借鉴的经验。

第五类是报告生成与知识整理。调度工作涉及大量的文档编写——值班日志、事件报告、运行分析报告等。系统需要能够根据运行数据和交互记录，自动生成结构化的报告草稿，减轻调度员的文档工作负担。

**功能分层设计**

从上述场景中提炼出的功能需求按照实现优先级被组织为三层：

核心层（Must-have）包括：规程条款精准检索与解释（支持条件查询和交叉引用追踪）、实时工况信息查询与可视化辅助、基本的调度建议生成（附安全约束校验）、多轮对话理解与上下文保持。

增强层（Should-have）包括：历史案例智能检索与类比分析、异常诊断辅助（结合SCADA告警数据）、调度方案与物理模型联合验证、值班日志和事件报告自动生成。

扩展层（Nice-to-have）包括：调度知识的自动学习与更新建议、跨工程知识迁移（将一个工程的经验应用到另一个工程）、自然语言驱动的数据分析与可视化、调度培训和知识考核模块。

项目的一期目标是完成核心层和增强层的全部功能，扩展层作为后续迭代的规划方向。

### 9.1.3 技术指标体系

需求分析的另一个关键产出是技术指标体系。项目组设计了四个维度的指标体系，每个维度包含若干可量化的指标，并设定了项目一期的目标值。

**响应性能指标**

首次令牌延迟（Time to First Token, TTFT）衡量用户提交查询后到系统开始生成回答之间的等待时间。考虑到调度场景的实时性要求，TTFT的目标值设定为$\leq 2$秒（包括检索、上下文构建和推理启动的全部时间）。完整响应时间（从查询到回答完成）的目标值设定为$\leq 15$秒（对于需要物理模型验证的查询，允许放宽至$\leq 30$秒）。系统并发处理能力要求同时支持至少10个独立对话会话，峰值吞吐不低于每分钟30次查询。

**知识准确性指标**

规程查询准确率衡量系统对调度规程相关问题回答的正确性，评估时采用水利专家人工判定。目标值为$\geq 95\%$（核心条款查询）和$\geq 85\%$（需要多条款综合推理的查询）。术语理解准确率衡量系统对水利专业术语的识别和解释正确性，目标值为$\geq 98\%$（常用术语，约2000个）和$\geq 90\%$（低频术语，约5000个）。数值计算正确率衡量系统在涉及数值推理（如流量计算、水位换算）时的准确性，目标值为$\geq 90\%$。

**安全性指标**

安全关键信息的错误率必须控制在极低水平。所谓安全关键信息，是指直接影响闸门操作、水位控制等可能导致工程事故的信息。安全关键信息的错误率目标值为$\leq 0.1\%$（即每1000次涉及安全关键内容的回答中，错误不超过1次）。此外，系统在识别超出自身能力范围的查询时，应主动声明不确定性并建议人工判断，漏报率目标值为$\leq 5\%$。

**用户体验指标**

用户满意度通过定期问卷调查评估，采用五级量表，目标平均分$\geq 4.0$。对话自然度由专家评审员评估系统对话的流畅性和专业性，目标为$\geq 3.8$（五级量表）。任务完成率衡量用户提出的查询中，系统能够给出有效回答（不论是直接回答还是引导到正确的信息源）的比例，目标值为$\geq 90\%$。

[表9-1: 瀚铎水网大模型技术指标体系]

| 维度 | 指标 | 目标值 | 评估方法 |
|------|------|--------|---------|
| 响应性能 | TTFT | $\leq 2$s | 系统日志统计 |
| 响应性能 | 完整响应时间 | $\leq 15$s | 系统日志统计 |
| 响应性能 | 并发能力 | $\geq 10$会话 | 压力测试 |
| 知识准确性 | 规程查询准确率 | $\geq 95\%$ | 专家评审 |
| 知识准确性 | 术语理解准确率 | $\geq 98\%$ | 标准测试集 |
| 知识准确性 | 数值计算正确率 | $\geq 90\%$ | 标准测试集 |
| 安全性 | 安全关键错误率 | $\leq 0.1\%$ | 专家评审+在线监控 |
| 安全性 | 能力范围识别漏报率 | $\leq 5\%$ | 边界测试集 |
| 用户体验 | 满意度均分 | $\geq 4.0$/5 | 问卷调查 |
| 用户体验 | 任务完成率 | $\geq 90\%$ | 使用日志分析 |

---

## 9.2 系统总体架构设计

### 9.2.1 五层架构：从数据到服务

瀚铎水网大模型的系统架构采用五层设计，自下而上依次为数据层、知识层、模型层、引擎层和服务层。这一架构的设计原则是关注点分离——每一层负责解决特定的技术问题，层间通过标准化接口通信，使得各层可以独立演进和替换。

[图9-1: 瀚铎水网大模型五层架构示意图]

**数据层（Data Layer）**

数据层是整个系统的基础，负责管理三类数据源。

第一类是结构化运行数据，来自SCADA系统和各类监测设备。这些数据包括水位、流量、闸门开度、水质参数等实时测量值，以及设备状态、告警记录等事件数据。数据通过OPC UA协议从SCADA系统采集，经过质量筛查（剔除明显的传感器故障值、填补短时缺失值）后存入时序数据库（InfluxDB）。

第二类是非结构化文档数据，包括调度规程、技术标准、设计文件、运行手册、历史事件报告、值班日志、会议纪要等。这些文档涵盖PDF、Word、扫描件等多种格式，总量超过50万页。文档数据经过格式统一、OCR识别（针对扫描件）和结构化解析后存入文档管理系统。

第三类是知识图谱数据，即从前两类数据中提取和构建的结构化知识（详见9.3节）。知识图谱数据存储在图数据库（Neo4j）中，包括实体（工程设施、设备、参数、规程条款等）、关系（空间拓扑、因果关联、约束依赖等）和属性（数值范围、时间有效性等）。

数据层的核心挑战在于异构数据源的统一接入和数据质量保证。项目实施过程中的经验表明，数据质量问题消耗了约30%的开发工时——远超最初的预估。最典型的问题包括：不同时期编制的规程文件使用不一致的术语命名、SCADA系统的测点编号与设计文件中的编号不对应、历史值班日志的记录格式随人员变化而不统一等。

**知识层（Knowledge Layer）**

知识层在数据层之上，负责将原始数据转化为结构化、可检索、可推理的知识表示。知识层包含三个核心组件。

知识图谱引擎管理水利领域知识图谱的构建、存储、查询和更新。它提供图查询接口（基于Cypher查询语言的封装），支持多跳推理（例如，从"3号闸门"出发，经过"属于→3号节制闸"→"位于→干渠K23+500"→"上游相邻→2号节制闸"的推理链，获取上游设施信息）。

向量知识库引擎管理文档的向量化表示和语义检索。文档经过分块、嵌入、索引后存入向量数据库（Milvus），支持语义相似度检索和混合检索（详见9.5节）。

知识融合引擎负责将知识图谱查询结果和向量检索结果进行融合排序，为上层的模型推理提供统一的知识上下文。融合策略在第五章5.4节已有理论讨论，此处的工程实现采用了加权互排序融合（Weighted Reciprocal Rank Fusion），其中知识图谱结果的权重根据查询类型动态调整——对于实体关系类查询（如"3号闸门的设计最大开度是多少"），知识图谱结果的权重较高；对于语义理解类查询（如"冰期调度需要注意什么"），向量检索结果的权重较高。

**模型层（Model Layer）**

模型层是系统的"大脑"，包含经过领域适配的大语言模型及其推理服务。

模型层的核心是瀚铎基座模型——一个基于Qwen2.5-72B进行领域继续预训练和指令微调的水利领域大语言模型（详见9.4节）。模型通过vLLM推理框架部署，支持连续批处理（continuous batching）和PagedAttention显存管理，在4×NVIDIA A100-80G GPU集群上运行。

模型层还包含若干辅助模型：嵌入模型（用于文档和查询的向量化，基于BGE-large-zh-v1.5微调）、重排序模型（用于对检索结果进行精细排序，基于BGE-reranker-v2-m3微调）、意图分类模型（用于对用户查询进行意图识别和路由，基于BERT微调的轻量级分类器）。

模型层通过统一的API接口（OpenAI-compatible API格式）向上层提供推理服务，使得引擎层不需要关心底层模型的具体实现和部署细节。

**引擎层（Engine Layer）**

引擎层是系统的"核心处理器"，实现了第六章讨论的认知AI引擎的完整功能。引擎层接收用户的自然语言查询，经过意图识别、知识检索、上下文构建、模型推理、输出审核等一系列处理步骤，生成最终的回答。

引擎层的核心组件包括：

对话管理器（Dialogue Manager）负责多轮对话的状态跟踪和上下文管理。它维护每个对话会话的状态（包括对话历史、当前工况上下文、用户意图序列等），并根据对话状态决定当前轮次的处理策略。

任务编排器（Task Orchestrator）负责将复杂查询分解为可执行的子任务序列，并协调各个子任务的执行。例如，对于查询"比较今天的流量分配方案与上周同期的差异"，任务编排器会生成以下子任务序列：(1) 获取今日流量分配数据；(2) 获取上周同期流量分配数据；(3) 进行对比分析；(4) 生成对比报告。

安全审核器（Safety Auditor）对系统生成的每一条涉及操作建议的回答进行安全检查，确保建议不违反安全包络约束。安全审核器的设计原则是"宁可误报、不可漏报"——当存在任何不确定性时，系统会明确标注并建议人工确认。

物理验证接口（Physics Validation Interface）是引擎层与物理AI引擎之间的桥梁。当认知AI引擎生成了涉及闸门调整的操作建议时，该接口将建议方案发送给物理AI引擎进行水力学仿真验证，并将验证结果反馈给认知AI引擎用于修正或确认方案（详见9.7节）。

**服务层（Service Layer）**

服务层是系统面向用户的最外层，提供多种交互方式。

Web对话界面是最主要的交互方式，嵌入到调度中心的业务系统中。界面设计遵循"最小干扰"原则——以侧栏形式呈现，不遮挡调度员的主要工作界面（SCADA监控画面），支持文本输入、语音输入和预置快捷查询。

API服务接口供HydroOS和其他业务系统调用。例如，HydroOS的告警处理模块可以自动调用瀚铎大模型的异常诊断功能，将告警信息转化为诊断建议附加到告警消息中。

移动端应用为不在调度中心现场的管理人员提供远程查询能力，支持基本的工况查询和报告浏览功能。

### 9.2.2 与HydroOS的集成接口

瀚铎水网大模型并非一个孤立的系统，它是HydroOS水网操作系统生态的有机组成部分。在CHS体系中，HydroOS提供水网运行的统一操作平台，瀚铎大模型作为认知AI引擎嵌入其中，与物理AI引擎、调度引擎、监控引擎等组件协同工作。

瀚铎大模型与HydroOS之间的集成通过三类接口实现。

**数据订阅接口**：瀚铎大模型通过HydroOS的数据总线订阅实时运行数据。数据总线基于Apache Kafka实现，瀚铎大模型作为消费者订阅以下主题（Topic）：实时测量数据（水位、流量、闸门开度等，1秒更新频率）、告警事件数据（SCADA告警、异常检测告警等）、调度指令数据（调度引擎下发的控制指令）、系统状态数据（各组件的运行状态和健康度）。订阅数据经过引擎层的上下文管理器处理后，维护一个"当前工况快照"——包括所有关键监测点的最新值、活跃告警列表、正在执行的调度任务列表等。当调度员提出查询时，这个工况快照会自动作为上下文信息注入到模型的提示词中，使得模型的回答总是基于最新的运行状态。

**服务调用接口**：瀚铎大模型与HydroOS的其他引擎之间通过gRPC接口进行服务调用。最重要的是与物理AI引擎的交互：瀚铎大模型可以调用物理AI引擎的水力仿真服务（输入初始条件和控制方案，获取预测的水位和流量变化过程）、调用优化求解服务（输入目标函数和约束条件，获取最优控制方案）、以及调用降阶模型服务（获取特定渠段的传递函数参数用于快速估算）。反过来，HydroOS的其他组件也可以调用瀚铎大模型的自然语言处理服务，例如将结构化的仿真结果转化为自然语言描述，或者对调度员输入的自然语言指令进行理解和结构化。

**事件通知接口**：当瀚铎大模型在处理用户查询过程中发现需要引起关注的情况（例如，调度员的操作建议违反了安全约束、知识库中的某项信息与当前运行状态不一致等），它会通过HydroOS的事件总线发布通知事件。这些事件会被相关的处理模块接收并进一步处理——例如，安全约束违反事件会触发HydroOS的安全联锁检查流程。

### 9.2.3 部署拓扑与基础设施

瀚铎水网大模型的部署采用"中心+边缘"的混合架构，兼顾推理性能和可用性。

**中心节点**部署在工程管理局的数据中心，承载系统的全部功能。中心节点的硬件配置包括：4×NVIDIA A100-80G GPU服务器（用于大模型推理）、2×高性能CPU服务器（用于检索引擎和知识图谱）、1×存储服务器（NVMe SSD阵列，用于向量数据库和时序数据库）。所有服务通过Kubernetes集群编排和管理，支持自动伸缩和故障恢复。

**边缘节点**部署在各管理所的就近机房，运行轻量级的推理服务。边缘节点使用量化后的小模型（7B参数量级），能够处理简单的规程查询和工况信息查询，在中心节点不可达时提供降级服务。边缘节点与中心节点之间通过专用网络连接，正常情况下边缘节点将复杂查询转发到中心节点处理。

这种混合架构的设计考虑了水利工程的特殊需求。调水工程的管理所通常分布在数百公里的线路上，网络条件参差不齐。在极端天气（暴风雨、冰灾等）可能导致网络中断的情况下——而这恰恰是最需要智能辅助的时候——边缘节点能够独立提供基本的决策支持服务，确保关键时刻不掉链子。

**网络与安全设计**

考虑到水利工程SCADA系统的安全等级要求，瀚铎大模型的网络架构严格遵循信息安全等级保护要求。系统部署在工程专网内，与互联网物理隔离。模型的权重文件和知识库数据存储在加密存储卷中。所有服务间通信采用mTLS双向认证。用户身份认证与工程管理局现有的统一认证系统集成，支持基于角色的访问控制——不同角色的用户能够访问的知识范围和操作权限不同。

所有用户交互记录（查询内容、系统回答、用户反馈）完整保存在审计日志中，日志数据采用只追加（append-only）存储，保留期限不少于3年，满足事后追溯和合规审查的需求。

---

## 9.3 水利知识体系构建

知识体系是瀚铎水网大模型的"学识根基"。无论模型本身的推理能力多么强大，如果知识基础不完善、不准确，系统就无法给出可靠的回答。本节详细描述知识体系构建的完整实践过程。

### 9.3.1 知识图谱构建实践

第三章系统阐述了水利知识图谱的理论框架和构建方法。本节聚焦于瀚铎项目中知识图谱构建的工程实践——理论到实践的距离，有时比想象中更远。

**本体设计**

知识图谱构建的第一步是本体设计，即定义图谱中的实体类型、关系类型和属性模式。项目组基于第三章3.2节提出的水利领域本体框架，结合胶东调水工程的具体特征进行了定制化设计。

经过三轮迭代，最终确定的本体包含12类实体、18种关系和47项属性。实体类型层级结构如下：

工程实体（Engineering Entity）包括：水利工程（Water Project，如"胶东调水工程"）、水系单元（Hydraulic Unit，如"黄水东调干渠"）、工程节点（Engineering Node，如"K23+500节制闸"）、设备（Equipment，如"3号平板闸门"）。

参数实体（Parameter Entity）包括：物理量（Physical Quantity，如"水位"、"流量"）、监测点（Monitoring Point，如"MP-0312-WL"）、设计参数（Design Parameter，如"设计流量50m³/s"）。

规程实体（Regulation Entity）包括：规程文件（Regulation Document，如"《胶东调水工程调度规程（2024版）》"）、规程条款（Regulation Clause，如"§4.3.2 汛期闸门控制"）、操作规程（Operation Procedure，如"OP-2024-017 冰期闸门操作规程"）。

事件实体（Event Entity）包括：历史事件（Historical Event，如"2024年7月暴雨超标事件"）、告警事件（Alarm Event，如"ALM-20240715-003 水位超限告警"）。

关系类型的设计遵循"精确而非求全"的原则——每种关系都有明确的领域语义，而不是使用泛化的"相关"关系。核心关系包括：空间拓扑关系（上游-下游、包含-属于、相邻）、功能关系（控制-被控制、监测-被监测）、约束关系（限值约束、条件约束、时间约束）、因果关系（触发、导致、缓解）。

[图9-2: 胶东调水工程知识图谱本体结构示意图]

**实体抽取与关系抽取**

知识图谱中的实体和关系来自两个渠道：结构化数据直接映射和非结构化文档信息抽取。

结构化数据映射相对直接。SCADA系统的设备台账提供了设备实体及其属性（名称、型号、安装位置、设计参数等），GIS数据提供了空间拓扑关系，运行数据库提供了监测点与设备之间的关联。这部分数据通过ETL（Extract-Transform-Load）流水线自动导入，映射规则由领域专家审定。在初次导入时，结构化数据产生了约12,000个实体和35,000条关系。

非结构化文档的信息抽取是更具挑战性的部分。项目组采用了"LLM+人工审核"的半自动化流水线：

第一步，文档预处理。将PDF、Word等格式的文档转换为统一的文本格式。对于含有表格的文档（调度规程中大量存在），使用专门的表格识别模型提取表格内容并保持结构。对于扫描件，使用OCR引擎（PaddleOCR）进行文字识别，识别准确率在95%以上。

第二步，大模型辅助抽取。将预处理后的文本分段送入大语言模型（初期使用通用模型，后期切换为瀚铎基座模型），通过精心设计的提示词模板指导模型从文本中抽取实体和关系。例如，对于调度规程文本，提示词模板要求模型识别：提及的所有工程设施及其属性、操作条件（何种工况下执行何种操作）、数值约束（最大/最小允许值）、条款之间的引用关系等。

第三步，人工审核与修正。大模型抽取的结果由领域专家进行逐条审核。审核采用三级评判标准：正确（直接采纳）、部分正确（修正后采纳）、错误（丢弃）。项目的实际统计数据显示，大模型辅助抽取的准确率约为82%（正确率62%+部分正确率20%），错误率18%。这意味着每100条抽取结果中，大约82条经过少量或无需修改即可采纳，仍需人工处理约18条错误。

第四步，一致性检验。将审核通过的实体和关系导入知识图谱后，运行一组预定义的一致性检查规则。例如：设备的上下游关系是否形成了无环的有向图（如果出现环路，说明关系抽取有误）、同一设备的多个参数值是否在合理范围内（如流量不可能为负数）、规程条款的引用关系是否都指向存在的条款等。一致性检验在初次导入时发现了约340条不一致记录，占总记录数的2.3%。

经过上述流程，瀚铎项目的知识图谱最终包含约28,000个实体、92,000条关系，覆盖了胶东调水工程的主要工程设施、设备参数、运行规程和历史事件。

**知识图谱维护与更新**

知识图谱不是一次性构建的静态产物，而是需要持续维护和更新的"活"知识库。瀚铎项目建立了三种知识更新机制。

计划性更新针对新版调度规程发布、工程改造完成、设备更换等可预见的知识变更事件。系统管理员通过知识管理工具触发更新流程，新版文档经过上述抽取-审核-检验流程后导入知识图谱，同时标记旧版知识的过期状态。

事件驱动更新针对运行过程中发现的知识缺陷。当调度员在与系统交互过程中发现回答不准确（可能源于知识图谱中的错误或缺失），可以通过反馈按钮提交修正建议。系统管理员定期审核这些反馈，确认有效的修正并更新知识图谱。

自动发现更新是一种探索性机制。系统在日常运行中持续比对知识图谱中的信息与实时运行数据，当发现持续性偏差时（例如，知识图谱中记录某闸门的最大开度为2.0m，但运行数据显示该闸门多次被操作到2.2m的开度），系统会生成一条"疑似知识过期"提醒，供系统管理员核实。

### 9.3.2 领域语料库建设

领域语料库是模型训练和RAG检索的基础。与知识图谱的结构化表示不同，语料库保持了文档的原始文本形态，为模型提供丰富的语义信息和领域表达模式。

**语料来源与规模**

瀚铎项目的领域语料来自五个渠道：

第一渠道是工程技术文档，包括调度规程（12份，约20万字）、技术标准（38份，约150万字）、设计文件（工程设计报告、施工图说明等，约80万字）、运行手册（设备操作手册、维护手册等，约45万字）。

第二渠道是运行记录，包括值班日志（2020年以来，约60万条记录，约300万字）、事件报告（约1,200份，约150万字）、会议纪要（约400份，约50万字）。

第三渠道是学术文献，包括水利工程运行管理相关的中文学术论文（约3,000篇，约600万字）、英文学术论文的翻译版本（约500篇，约150万字）、教材章节（水力学、水利工程管理等教材的相关章节，约200万字）。

第四渠道是标准规范，包括国家和行业标准中与水利工程运行相关的部分（约100份，约300万字）。

第五渠道是内部培训材料，包括调度员培训课件、考核题库和经验交流材料（约100万字）。

五个渠道的语料总量约为2000万字（中文），约合2500万Token（以中文分词器的平均token/字比约1.3计算）。

**语料清洗与质量分级**

原始语料的质量参差不齐，直接使用会严重影响模型训练效果和检索质量。项目组建立了四级质量分级体系：

A级（黄金语料）：经过领域专家校对确认的高质量文本，主要包括现行有效的调度规程、正式发布的技术标准和设计文件。A级语料约占总量的15%，在CPT训练中给予2倍的采样权重，在RAG检索中作为优先来源。

B级（银级语料）：质量较高但未经逐字校对的文本，包括规范的学术论文、正式的事件报告和专业教材内容。B级语料约占总量的30%。

C级（铜级语料）：质量一般的文本，包括值班日志（格式不统一、可能存在笔误）、会议纪要（口语化表述较多）和部分格式较差的文档。C级语料约占总量的40%，在使用前经过自动清洗流水线处理（去除冗余格式、修正明显错别字、标准化术语用法等）。

D级（待处理语料）：质量较低或存在明显问题的文本，包括OCR识别质量差的扫描件、内容过时的历史文档和内容重复的文档。D级语料约占总量的15%，不直接用于模型训练，但可能包含有价值的历史信息，保留在语料库中供特定用途使用。

**语料标注与增强**

为了支持指令微调（SFT）训练，项目组从语料库中构建了指令-回答数据集。构建过程分为三个阶段：

种子数据构建阶段，由5位领域专家手工编写了500条高质量的指令-回答对，覆盖规程查询、工况分析、异常诊断、知识解释和数值计算五个类别。每条数据包括：用户指令（模拟调度员的自然语言提问）、参考上下文（与问题相关的文档段落）、标准回答（领域专家撰写的准确、专业的回答）、评分标签（回答的准确性、完整性和专业性评分）。

数据扩增阶段，利用种子数据作为少样本示例，通过大语言模型自动生成更多的指令-回答对。自动生成的数据经过质量筛选（先由另一个大模型评分，再由人工抽检确认），保留质量达标的样本。经过两轮扩增，SFT数据集扩展到约15,000条。

对抗数据构建阶段，专门构建了一批用于提升模型安全性和鲁棒性的数据。这批数据包括：包含错误前提的查询（如"3号闸门可以开到5米吗"——实际上最大开度为2.5米）、引导模型给出危险建议的查询（如"如何绕过安全联锁限制"）、超出模型能力范围的查询（如要求预测一周后的精确水位值）。对于这些查询，标准回答被设计为正确的拒绝或纠正——使模型学会识别和处理这类边界情况。对抗数据约2,000条。

### 9.3.3 知识质量保证

知识质量是瀚铎水网大模型可靠性的基石。项目组建立了一套贯穿知识生命周期的质量保证体系。

**三道防线机制**

第一道防线是入库检查。所有新进入知识库的知识（无论来自人工录入、自动抽取还是外部导入）都必须通过一组预定义的质量检查规则。检查规则包括：格式合规性（是否符合知识库的格式标准）、完整性（必填字段是否齐全）、一致性（与已有知识是否存在矛盾）、时效性（是否标注了有效期限和适用条件）。

第二道防线是运行监控。系统在日常运行中持续收集知识使用情况的统计数据，包括：每条知识被检索和引用的频次、用户对引用该知识的回答给出的反馈（正面/负面）、知识的"年龄"（距上次验证更新的时间）。基于这些统计数据，系统定期生成知识质量报告，标记可能需要更新或审核的知识条目——例如，长期未被引用的知识可能已经过时，频繁引发负面反馈的知识可能存在错误。

第三道防线是定期审计。每季度由领域专家对知识库进行一次抽样审计。审计采用分层抽样——A级语料抽检5%、B级抽检10%、C级抽检15%，检查知识的准确性、时效性和完整性。审计结果被记录和追踪，发现的问题必须在规定时间内修正。

**知识冲突处理**

在大型知识库中，知识冲突是不可避免的。常见的冲突类型包括：新旧版本冲突（新版规程修改了某些条款但旧版内容未完全清除）、跨源冲突（不同来源的文档对同一参数记录了不同的数值）、隐含冲突（两条知识单独看都正确，但在特定条件下组合推理会产生矛盾结论）。

瀚铎项目采用"检测-标记-裁决-记录"四步冲突处理流程：

检测环节通过规则引擎自动扫描知识库，识别潜在的冲突。检测规则包括：同一实体的同一属性存在不同取值、同一操作条件下存在不同的操作指导、数值范围存在重叠或矛盾等。

标记环节将检测到的潜在冲突记录到冲突管理台账中，标注冲突类型、涉及的知识条目和检测时间。

裁决环节由系统管理员组织领域专家对冲突进行裁决。裁决的核心原则是"新优先于旧、正式优先于非正式、精确优先于粗略"——即新版规程优先于旧版、正式发布的文件优先于内部讨论记录、标注了具体工况条件的知识优先于笼统描述。

记录环节将裁决结果和裁决依据完整记录。被裁决为过时或错误的知识不会被删除，而是被标记为"已作废"并附注替代知识的链接，保留历史可追溯性。

---

## 9.4 基座模型选型与领域适配训练

### 9.4.1 基座模型评估与选型

选择合适的基座模型是领域大模型建设的关键决策。项目组对六个候选基座模型进行了系统评估。

**候选模型**

根据第四章4.3节讨论的选型框架，项目组从以下维度筛选候选模型：中文理解能力（水利文档以中文为主）、长上下文窗口（调度规程文档较长）、开源可控（部署在工程专网内，不能依赖云API）、模型规模（需要在合理的硬件成本内运行）。筛选后进入评估的候选模型包括：Qwen2.5-72B、Qwen2.5-32B、DeepSeek-V2.5-67B、Llama3.1-70B、Yi-1.5-34B和ChatGLM4-9B。

**评估方法**

评估采用三级测试框架：

第一级是通用能力基准测试，使用CMMLU、C-Eval等中文通用评测基准，评估候选模型的基线中文理解和推理能力。这一级测试的目的是确认候选模型具备足够强的通用基础能力——如果基础能力不足，领域微调也难以弥补。

第二级是领域知识预测试，使用项目组自建的"HydroEval-500"测试集（包含500道水利领域选择题和简答题，涵盖水力学基础、调度管理、设备知识、规程理解四个方面），评估候选模型在水利领域的"零样本"表现。这一级测试评估的是模型的领域知识储备和专业推理能力。

第三级是RAG集成测试，将候选模型与简化版的RAG系统集成，在20个典型查询场景下测试模型利用检索到的上下文信息回答问题的能力。这一级测试评估的是模型在有外部知识支持时的综合表现，更接近实际使用场景。

**评估结果**

[表9-2: 基座模型评估结果汇总]

| 模型 | 参数量 | CMMLU | C-Eval | HydroEval-500 | RAG集成 | GPU需求 |
|------|-------|-------|--------|---------------|---------|---------|
| Qwen2.5-72B | 72B | 83.2 | 84.5 | 41.3 | 72.8 | 4×A100 |
| Qwen2.5-32B | 32B | 79.1 | 80.3 | 37.8 | 68.2 | 2×A100 |
| DeepSeek-V2.5 | 67B(MoE) | 82.7 | 83.1 | 39.5 | 71.4 | 3×A100 |
| Llama3.1-70B | 70B | 78.5 | 74.2 | 28.7 | 64.5 | 4×A100 |
| Yi-1.5-34B | 34B | 76.8 | 78.9 | 35.2 | 65.8 | 2×A100 |
| ChatGLM4-9B | 9B | 72.1 | 73.5 | 32.4 | 61.3 | 1×A100 |

注：CMMLU、C-Eval为百分制，HydroEval-500为简答题专家评分（百分制），RAG集成为场景测试通过率（百分制）。

评估结果表明，Qwen2.5-72B在所有三个层级的测试中均表现最优。特别值得注意的是：

在领域知识预测试（HydroEval-500）中，所有候选模型的表现都不理想（最高仅41.3分），证实了第四章所述的通用模型在水利领域的知识欠缺问题。但Qwen2.5-72B和DeepSeek-V2.5在涉及基本水力学概念的题目上表现尚可（约60分），薄弱环节主要在调度规程理解和工况推理方面。

在RAG集成测试中，大参数模型的优势更加明显。Qwen2.5-72B能够较好地利用检索到的上下文信息，在回答中正确引用了85%的关键信息点；而较小模型（如ChatGLM4-9B）在面对长上下文时出现了明显的信息遗漏和幻觉。

最终选型决策如下：主力推理模型选择Qwen2.5-72B，用于中心节点的全功能部署；边缘节点的降级服务使用Qwen2.5-7B（72B模型的蒸馏版本），在经过领域微调和INT4量化后可在单张RTX 4090上运行。

### 9.4.2 继续预训练（CPT）实施

继续预训练的目的是将水利领域知识"内化"到模型的参数中，使模型不仅能够在有RAG支持时表现良好，还能在独立推理时展现出基本的领域知识储备。

**语料准备**

CPT语料从9.3.2节描述的领域语料库中选取，按照质量分级进行差异化处理。

A级语料（约300万字）以原文形态使用，在训练数据中重复出现3次（等效于3倍采样权重），确保模型充分吸收这部分最权威的知识。

B级语料（约600万字）经过轻度清洗（格式标准化、去除页眉页脚等非正文内容）后使用，重复1次。

C级语料（约800万字）经过深度清洗（自动纠错、术语标准化、去重）后使用，不重复。

D级语料不参与CPT训练。

此外，为了防止灾难性遗忘（catastrophic forgetting），CPT语料中混入了约20%的通用中文语料（从开源的WuDaoCorpora中采样），保持模型的通用语言理解能力。

CPT语料的最终规模约为3000万Token（领域语料）+ 750万Token（通用语料）≈ 3750万Token。

**训练配置**

训练采用DeepSpeed ZeRO-3并行策略，在8×A100-80G GPU集群上进行。关键超参数的设定基于预实验调参：

学习率采用余弦衰减调度，峰值学习率$2 \times 10^{-5}$（约为预训练学习率的1/10），预热步数500步（约占总训练步数的5%）。学习率的选择经过了$\{1\times 10^{-5}, 2\times 10^{-5}, 5\times 10^{-5}\}$三个值的对比实验——$5\times 10^{-5}$在训练后期出现了明显的通用能力退化，$1\times 10^{-5}$的领域知识吸收速度过慢，$2\times 10^{-5}$在两者之间取得了较好的平衡。

批量大小设置为全局批量4M Token/步（每GPU 512K Token × 8 GPU），序列长度8192 Token，梯度累积4步。

训练总步数约9,000步（3750万Token / 4M Token/步 ≈ 9,375步），总训练时间约72小时。

**训练监控与中间评估**

训练过程中每500步进行一次中间评估，评估指标包括：

领域困惑度（Domain Perplexity）：在A级语料的保留集上计算。CPT训练使模型的领域困惑度从基座模型的18.7下降到7.2，说明模型对水利领域文本的"理解"能力显著提升。

通用能力保持率：在CMMLU和C-Eval的子集上评估。训练结束后，CMMLU得分从83.2略降至81.5（保持率97.9%），C-Eval得分从84.5略降至82.8（保持率98.0%），通用能力基本保持。

HydroEval-500成绩：从基座的41.3分提升至58.6分（+17.3），提升主要来自水力学基础知识和调度管理知识方面，规程理解的提升相对有限——这是符合预期的，因为规程理解需要更精细的指令微调来提升。

### 9.4.3 指令微调（SFT）实施

指令微调的目标是使经过CPT的模型能够按照用户的指令格式给出结构化、专业的回答，而不仅仅是"续写"文本。

**数据准备**

SFT数据集包括三部分，共约17,000条：

领域指令数据约15,000条（来自9.3.2节的数据构建流程），格式为{系统提示, 用户指令, 助手回答}三元组。系统提示统一设定为瀚铎大模型的角色定位文本，包括身份声明（"你是瀚铎水网大模型，专为水利工程运行管理设计"）、能力边界说明（"你可以回答关于调度规程、工况分析、设备知识等方面的问题，但不能替代专业工程师的判断"）和行为准则（"回答应当准确、专业、简洁；不确定时应明确说明；涉及安全的建议应附注验证提示"）。

对抗数据约2,000条（来自9.3.2节的对抗数据构建），用于增强模型的安全性和鲁棒性。

通用指令数据约5,000条（从开源的ShareGPT-zh数据集中筛选，去除与水利领域可能矛盾的样本），用于保持模型的通用对话能力。数据去重后取约3,000条使用。

最终SFT数据集总计约17,000条，训练集与验证集的比例为9:1。

**训练配置**

SFT训练采用全参数微调（Full Fine-tuning），而非LoRA等参数高效方法。这一选择基于以下考虑：(1) 项目组拥有足够的GPU资源支持全参数微调；(2) 预实验表明在数据量约17,000条的规模下，全参数微调相比LoRA-64在HydroEval-500上的表现高出约3分，且在长上下文场景中的优势更为明显；(3) 全参数微调后的模型可以直接部署，无需额外的LoRA权重合并步骤。

训练采用AdamW优化器，学习率$1 \times 10^{-5}$，余弦衰减，预热比例3%。训练3个epoch（约经验表明领域SFT在2-4个epoch时效果最佳，更多epoch容易过拟合到训练数据的特定表达模式）。

训练损失仅计算助手回答部分（instruction masking），不对系统提示和用户指令部分的token计算损失——这是指令微调的标准做法，使模型专注于学习如何生成高质量的回答。

**训练结果**

SFT训练后模型的评估结果：

HydroEval-500成绩从CPT后的58.6分提升至71.8分（+13.2），提升主要来自规程理解（+18.5分）和工况推理（+15.2分）两个方面——这正是指令微调的预期效果。

在RAG集成测试中，模型的场景通过率从CPT后的79.2%提升至88.5%，特别是在需要综合多个文档段落回答的复杂查询场景中，表现提升最为显著。

在安全性测试中，模型对对抗查询的正确拒绝率达到96.2%（500条对抗测试样本中正确拒绝481条），误拒率为3.8%——误拒率虽然稍高，但在安全优先的设计原则下是可以接受的。

### 9.4.4 偏好优化（DPO）实施

偏好优化是训练流程的最后一步，目标是使模型的回答风格更贴近水利专业人员的期望，特别是在回答的详略程度、专业术语使用频率和安全提示措辞等方面进行微调。

**偏好数据构建**

DPO训练需要成对的偏好数据，即对于同一个用户指令，提供一个"优选回答"（chosen）和一个"劣选回答"（rejected）。项目组采用了以下策略构建偏好数据：

方法一：从SFT模型的多次采样中选择。对于每个指令，让SFT模型在不同温度参数下生成5个候选回答，然后由领域专家根据预定义的偏好准则评选最优和最差回答。偏好准则包括：事实准确性（最高权重）、专业术语使用恰当性、回答结构清晰度、安全提示的适度性（既不遗漏也不过度渲染）、语言简洁性。通过这种方法构建了约3,000对偏好数据。

方法二：利用SFT模型生成的回答与专家撰写的标准回答配对。SFT模型的回答作为"劣选"，专家回答作为"优选"。这种方法利用了9.3.2节中种子数据的专家回答，构建了约500对偏好数据。

最终DPO数据集包含约3,500对偏好数据。

**训练配置**

DPO训练使用标准的Direct Preference Optimization算法（Rafailov et al., 2023），超参数$\beta=0.1$（控制偏好优化的强度，较小的值意味着更激进的优化）。学习率$5 \times 10^{-6}$（比SFT更小，防止过度偏离SFT后的分布），训练1个epoch。

**训练效果**

DPO训练的效果主要体现在"软指标"上，而非HydroEval-500这类硬指标的分数提升。具体来说：

专家盲评偏好率：从500对{DPO前回答, DPO后回答}的盲评中，专家偏好DPO后回答的比例为67.2%（336/500），偏好DPO前回答的比例为18.4%（92/500），认为二者相当的比例为14.4%（72/500）。

安全提示恰当性：DPO后模型在涉及操作建议的回答中，安全提示的措辞从"不建议在没有专业人员指导的情况下执行此操作"（过度保守）调整为更为专业的"此方案需经值班长确认后执行，建议同步核查3号闸门下游水位"（具体且可操作）。

回答长度分布：DPO后模型的平均回答长度从SFT阶段的342字减少到276字，减少了约20%。这反映了专家偏好准则中"简洁"维度的影响——调度场景下过长的回答反而会降低效率。

---

## 9.5 检索增强生成系统实现

第五章详细讨论了RAG技术的理论框架。本节描述瀚铎项目中RAG系统从设计到调优的完整实践过程。

### 9.5.1 文档处理与分块流水线

RAG系统的第一个工程挑战是将海量的异构文档转化为适合检索的知识块。

**文档格式统一**

瀚铎项目面对的文档格式包括PDF（约60%）、Word（约25%）、扫描件（约10%）和网页/其他格式（约5%）。文档处理流水线的第一步是格式统一——将所有文档转化为带有结构标注的Markdown格式。

PDF文档的处理采用分层策略：对于"原生"PDF（由Word等工具直接导出），使用PyMuPDF提取文本和表格；对于"图片"PDF（扫描件转PDF），先使用PaddleOCR进行文字识别，再使用布局分析模型（LayoutLMv3）识别标题、正文、表格、图注等结构元素。

表格处理是一个特殊的难点。调度规程中包含大量的参数表格（如不同水位对应的闸门开度查找表），这些表格对于回答查询至关重要，但传统的文本分块方法会破坏表格的行列结构。项目组的解决方案是：表格在Markdown中以完整的表格格式保留，在分块时将每个表格视为一个不可分割的原子单元，表格的标题和前后文说明作为该原子单元的上下文信息一同保存。

**分块策略**

经过反复实验，项目组最终采用"语义段落+滑动窗口"的混合分块策略：

首先按照文档的逻辑结构进行一级分块——以章节标题、编号条款等结构标记为分割点，将文档分割成语义完整的段落。一级分块的平均长度约为800-1200字。

对于超过1500字的大段落，使用滑动窗口进行二级分块——窗口大小1000字，步长700字（即相邻块之间有30%的重叠），确保跨句的语义信息不会被截断。

对于短于200字的小段落（如表格注释、简短的条款说明），与其前后相邻的段落合并，避免产生信息不足的"碎片"知识块。

每个知识块除了正文内容外，还附带以下元数据：来源文件标识、文件内的位置标识（章节号/页码）、质量等级（A/B/C/D）、生效日期和失效日期（如果适用）、关联的知识图谱实体ID列表。

最终处理产生约85,000个知识块，平均长度约820字（约1,050 Token）。

### 9.5.2 混合检索引擎

瀚铎项目的检索引擎采用"语义检索+关键词检索+知识图谱查询"的三路混合架构，融合三种检索范式的优势。

**语义检索路径**

语义检索基于向量相似度，能够理解查询和文档的语义关联。

嵌入模型选用BGE-large-zh-v1.5（BAAI出品），并在水利领域语料上进行了对比学习微调。微调数据来自SFT数据集中的{查询, 正例段落, 负例段落}三元组——正例段落是回答该查询所依赖的文档段落，负例段落是语义相关但不直接回答该查询的段落（即"困难负例"）。微调后的嵌入模型在水利领域的检索召回率（Recall@10）从基线的71.3%提升至84.7%。

向量索引使用Milvus向量数据库，索引类型为IVF_FLAT（倒排文件+精确距离计算），聚类中心数nlist=1024，查询时搜索的聚类数nprobe=64。这一配置在约85,000条文档的规模下，平均查询延迟约15ms，召回率损失小于1%。

**关键词检索路径**

关键词检索基于倒排索引，擅长精确匹配特定的术语、编号和数值。

检索引擎使用Elasticsearch，配置了水利领域专用的分词器——在jieba分词的基础上添加了约8,000个水利专业词汇的自定义词典，确保专业术语不被错误切分（例如，"节制闸"应作为一个完整词汇，而不是被切分为"节制"+"闸"）。

检索时采用BM25评分公式，并针对不同字段设置了差异化的权重：标题字段权重3.0、正文字段权重1.0、元数据字段权重0.5。

**知识图谱查询路径**

对于涉及实体关系的查询（如"3号闸门的上游是什么"、"这个规程条款引用了哪些其他条款"），系统首先在知识图谱中进行图查询，获取结构化的关系信息。

图查询的触发条件由意图分类模型判断——当查询被识别为"实体属性查询"或"关系查询"类型时，图查询路径被激活。图查询返回的结构化结果（实体属性值、关联实体列表等）被转化为自然语言文本，与语义检索和关键词检索的结果一同参与融合排序。

**三路融合策略**

三种检索路径的结果通过加权互排序融合（Weighted RRF）合并为统一的排序列表：

$$\text{score}(d) = \sum_{r \in \{semantic, keyword, graph\}} \frac{w_r}{k + \text{rank}_r(d)}$$

其中 $\text{rank}_r(d)$ 是文档 $d$ 在第 $r$ 种检索路径中的排名（未出现在某路径结果中的文档该项为$\infty$），$k$ 是平滑常数（项目中设为60），$w_r$ 是各路径的权重。

权重 $w_r$ 根据查询类型动态调整，由意图分类模型的输出驱动：

| 查询类型 | $w_{semantic}$ | $w_{keyword}$ | $w_{graph}$ |
|---------|---------------|--------------|-------------|
| 概念解释类 | 0.5 | 0.3 | 0.2 |
| 精确查找类 | 0.2 | 0.5 | 0.3 |
| 关系推理类 | 0.2 | 0.2 | 0.6 |
| 综合分析类 | 0.4 | 0.3 | 0.3 |

融合后取Top-8文档块进入重排序阶段。

**重排序**

重排序模型（基于BGE-reranker-v2-m3微调）对Top-8文档块与原始查询的相关性进行精细评分，重新排列顺序后取Top-5进入上下文构建阶段。重排序的引入使得最终上下文的命中率（Top-5中包含回答问题所需信息的比例）从78.3%提升至91.6%。

### 9.5.3 查询改写与上下文构建

**查询改写**

调度员的查询通常简短且带有强烈的上下文依赖。例如，在一段关于3号闸门的对话后，调度员可能只说"那4号呢？"——系统需要理解这是在问4号闸门的相同信息。

查询改写模块的功能是将用户的原始查询扩展为检索友好的完整查询。改写策略包括：

上下文补全：结合对话历史，将省略的指代和主题补全。使用瀚铎基座模型本身完成改写，提示词模板为："请将以下用户查询改写为一个自包含的完整查询，补全对话历史中的指代和隐含信息。只输出改写后的查询，不要添加任何解释。\n\n对话历史：{history}\n\n用户查询：{query}"。

多角度扩展：对于复杂查询，生成2-3个从不同角度表述的等价查询，分别进行检索后合并结果。例如，"冰期调度需要注意什么"可能被扩展为："冰期调度注意事项"、"冬季输水安全要求"、"冰盖工况操作规程"。

**上下文构建**

检索结果需要组装为模型的输入上下文。上下文构建遵循以下原则：

信息分层：上下文按照"运行状态→检索结果→系统指令"的顺序组织。首先注入当前工况快照（来自HydroOS数据订阅的最新运行数据），然后是检索到的知识块（按重排序得分从高到低排列），最后是系统级的行为指令。

标注来源：每个知识块在注入上下文时都标注了来源信息（文件名和位置），使模型能够在回答中引用来源，增强回答的可追溯性。

长度控制：上下文的总长度控制在6000 Token以内（在模型的8192 Token上下文窗口中，保留约2000 Token用于对话历史和生成回答）。当Top-5知识块的总长度超过4000 Token时，对排名靠后的知识块进行截断或摘要压缩。

上下文模板的简化示例如下：

```
[系统角色]
你是瀚铎水网大模型，专为水利工程运行管理设计。
当前时间：2025-08-15 14:32:00

[当前工况]
- 干渠总流量：42.3 m³/s（设计流量80%）
- 3号节制闸开度：1.2m，上游水位：23.45m，下游水位：22.18m
- 活跃告警：无
- 当前调度任务：日常输水

[参考知识]
[来源: 调度规程§4.3.2, A级]
汛期3号节制闸的开度上限受上游水位约束...
（知识块1内容）

[来源: 运行手册§7.1, B级]
3号节制闸为平板钢闸门，设计最大开度2.5m...
（知识块2内容）

[行为指令]
- 回答应基于上述参考知识，明确标注信息来源
- 涉及操作建议时附注安全提示
- 不确定时明确说明
```

---

## 9.6 认知AI引擎集成

引擎层是瀚铎水网大模型的"大脑中枢"，将前述的知识体系、训练模型和检索系统整合为一个连贯的认知处理流水线。

### 9.6.1 意图识别与任务路由

用户查询进入系统后的第一个处理步骤是意图识别。意图识别的准确性直接决定了后续处理路径的正确性——如果一个"关系查询"被误判为"概念解释"，系统可能会给出冗长的背景介绍而不是用户需要的简短答案。

**意图分类体系**

瀚铎项目定义了两级意图分类体系。一级意图（Intent Category）分为8类：规程查询（Regulation Query）、工况分析（Condition Analysis）、异常诊断（Anomaly Diagnosis）、历史检索（Historical Search）、知识解释（Knowledge Explanation）、操作建议（Operation Advice）、报告生成（Report Generation）和闲聊/其他（Chat/Other）。

每个一级意图下进一步细分为二级意图（Sub-intent）。例如，"规程查询"下包括：条款查找、条件查询、交叉引用、适用性判断四个二级意图。"异常诊断"下包括：告警解读、原因分析、处置建议、历史对比四个二级意图。

**分类模型**

意图分类采用轻量级BERT模型（chinese-bert-wwm-ext，110M参数），在约8,000条标注数据上微调。选择轻量级模型而非使用主力大模型进行意图分类的原因是：(1) 意图分类需要极低的延迟（<50ms），作为流水线的第一步不应成为瓶颈；(2) 意图分类是一个相对简单的分类任务，轻量级模型完全胜任；(3) 将意图分类与主力模型解耦，有利于系统的模块化维护和独立优化。

分类模型在测试集上的一级意图准确率为94.2%，二级意图准确率为87.6%。对于低置信度的分类结果（softmax概率<0.7），系统采用"保守路由"策略——默认选择"综合分析"路径，该路径会同时激活多种检索方式，虽然效率略低但能减少误判的影响。

**任务路由**

意图识别的结果驱动任务路由——决定查询应该经过怎样的处理流水线。

简单查询（如"3号闸门的设计最大开度是多少"）走快速路径：知识图谱直查→结果格式化→返回。这类查询的端到端延迟通常在1秒以内。

标准查询（如"冰期调度需要注意什么"）走标准RAG路径：查询改写→混合检索→重排序→上下文构建→模型推理→返回。端到端延迟通常在3-8秒。

复杂查询（如"请分析当前工况是否适合将流量从40提升到50"）走增强路径：查询分解→并行检索→物理模型验证→结果综合→模型推理→安全审核→返回。端到端延迟通常在10-20秒。

操作建议查询走安全增强路径：在标准或增强路径的基础上，增加安全审核环节和物理验证环节，且回答中必须包含安全提示和操作确认建议。

### 9.6.2 对话状态管理

瀚铎大模型支持多轮对话——调度员可以在一个连续的对话会话中逐步深入某个问题，每一轮的查询都在前几轮的基础上进行。对话状态管理的质量直接影响多轮交互的连贯性和准确性。

**对话状态模型**

每个对话会话维护一个对话状态对象，包含以下字段：

```python
class DialogueState:
    session_id: str            # 会话唯一标识
    user_id: str               # 用户标识
    user_role: str             # 用户角色（调度员/管理人员/...）
    created_at: datetime       # 会话创建时间
    turns: List[Turn]          # 对话轮次列表
    current_topic: str         # 当前讨论主题
    mentioned_entities: Dict   # 提及的实体（名称→知识图谱ID）
    active_constraints: List   # 活跃的上下文约束
    pending_actions: List      # 待确认的操作建议
```

对话状态在每一轮交互后更新。更新逻辑由一组规则驱动：

主题切换检测：当新一轮查询的意图类别与上一轮不同，或者提及了全新的工程设施时，判定为主题切换。主题切换时，清空`mentioned_entities`和`active_constraints`，但保留`turns`历史。

指代消解：当新一轮查询中出现"它"、"那个"、"上面的"等指代词时，结合`mentioned_entities`进行消解。消解策略采用"最近优先"原则——指代词优先指向最近一轮中提及的实体。

约束累积：当用户在对话中逐步添加条件时（如"假设上游水位再上升0.5米呢"），这些条件作为`active_constraints`累积，在后续的检索和推理中持续生效。

**对话历史压缩**

随着对话轮次增加，完整的对话历史可能超过模型的上下文窗口限制。对话管理器采用"摘要+近期完整"的压缩策略：保留最近3轮对话的完整内容，更早的对话被压缩为摘要形式（由模型生成一句话总结每轮对话的核心内容）。这种策略在保持近期上下文完整性的同时，将对话历史的Token开销控制在约500 Token以内。

### 9.6.3 安全审核与输出过滤

安全审核是认知AI引擎的最后一道防线。在水利工程领域，一个错误的操作建议可能导致严重的工程事故——例如，不当的闸门操作可能导致渠道溢出或断流。因此，安全审核不是一个可选的优化项，而是系统的核心功能。

**三层安全审核机制**

第一层是规则审核。系统维护了一组硬编码的安全规则，对模型输出进行模式匹配检查。例如：

- 闸门开度建议不得超过设计最大开度
- 水位变化速率建议不得超过安全限值
- 任何涉及"同时操作超过3座闸门"的建议必须标记为需要值班长确认
- 涉及"冰期"工况的操作建议必须包含防冰安全提示

规则库当前包含约120条安全规则，由领域专家编制和维护。规则审核的优势是确定性强、零延迟、不存在误判（只要规则正确），但覆盖面有限——只能检查已知模式的安全风险。

第二层是模型审核。使用一个独立的安全评估模型（基于Qwen2.5-7B微调的专用安全分类器），对模型输出进行语义级别的安全评估。评估维度包括：事实一致性（回答是否与检索到的知识一致）、安全合规性（建议是否违反安全约束）、不确定性表达（涉及不确定信息时是否做了适当声明）。安全评估模型为每条输出给出一个0-1的安全置信度分数。

第三层是人工确认触发。当安全置信度低于阈值（当前设为0.85）时，系统不会直接输出回答，而是附加明确的提示："以下建议需要值班长确认后执行，系统检测到以下不确定因素：[具体说明]"。

**幻觉检测与抑制**

大语言模型的"幻觉"（hallucination）问题在水利领域尤其危险——模型可能生成看起来专业但实际上不正确的数值或建议。瀚铎项目采用了多重幻觉检测机制：

来源验证：模型被要求在回答中标注信息来源（引用检索到的知识块编号）。系统自动检查模型标注的来源是否与回答内容一致——如果模型声称"根据调度规程§4.3.2"但回答内容与该条款实际内容不符，系统会标记为潜在幻觉。

数值合理性检查：对模型输出中的数值进行范围检查。例如，如果模型建议"将流量调整到200m³/s"，但知识图谱中记录该渠段的设计最大流量为50m³/s，系统会拦截并标记。

自一致性检查：对于复杂回答，系统将回答中的关键结论提取出来，让模型重新验证这些结论是否与提供的上下文一致。如果模型在验证阶段否定了自己的结论，说明原始回答可能存在幻觉。

实际运行数据显示，三层安全审核机制每月平均拦截约45条存在安全风险或幻觉的回答（约占总回答数的0.8%），其中规则审核拦截约60%、模型审核拦截约30%、人工确认触发约10%。

---

## 9.7 双引擎融合实践

第八章讨论了物理AI引擎与认知AI引擎融合的理论框架。本节展示瀚铎项目中双引擎融合的具体工程实现。

### 9.7.1 与物理AI引擎的接口设计

在HydroOS的架构中，物理AI引擎是一个独立的子系统，包含水力学仿真模型（基于Saint-Venant方程的非恒定流模型）、降阶模型（IDZ传递函数模型）和MPC优化求解器。瀚铎大模型（认知AI引擎）与物理AI引擎之间的交互通过一组标准化的gRPC接口实现。

**接口定义**

核心接口包括三个：

仿真请求接口（SimulationRequest）：认知AI引擎向物理AI引擎提交一个仿真任务，输入包括初始条件（当前水位、流量分布）、控制方案（各闸门开度的时间序列）和仿真时段。物理AI引擎执行水力学仿真后返回预测的水位和流量变化过程。该接口的响应时间取决于仿真的复杂度——对于单渠段仿真通常在2-5秒，全系统仿真可能需要30-60秒。

快速估算接口（QuickEstimate）：当只需要粗略的水力传播估算（如"上游流量变化多久会影响到下游某点"）时，认知AI引擎调用降阶模型的快速估算接口，响应时间在100ms以内。

优化求解接口（OptimizationRequest）：认知AI引擎提交一个优化问题——包括优化目标（如最小化水位偏差或能耗）和约束条件（安全包络、规程限值等），物理AI引擎的MPC求解器返回最优控制方案。

**数据格式转换**

双引擎之间最大的工程挑战之一是数据格式转换。认知AI引擎处理的是自然语言和半结构化信息，物理AI引擎处理的是数值矩阵和时间序列。

从认知到物理的转换：当调度员说"将3号闸门的流量增加20%"时，认知AI引擎需要将这句自然语言转化为物理AI引擎能够理解的数值参数——查询当前流量值（如35m³/s），计算目标流量（42m³/s），通过水力关系估算对应的闸门开度变化量，然后构建控制方案的数值格式提交给物理AI引擎。这个转换过程由引擎层的"语义-数值转换器"模块完成。

从物理到认知的转换：物理AI引擎返回的仿真结果是数值时间序列（各断面的水位和流量随时间的变化曲线）。认知AI引擎需要将这些数值结果"翻译"成调度员能够理解的自然语言描述——例如"方案执行后，下游K45+000断面的水位将在2小时后上升约0.3米，峰值水位23.8米仍在安全范围内（安全上限24.5米）"。这个转换由瀚铎大模型本身完成（通过专门的"仿真结果解读"提示词模板）。

### 9.7.2 方案验证闭环

当认知AI引擎生成了涉及操作建议的回答时，方案验证闭环被触发。这是双引擎协作最核心的场景。

**验证流程**

完整的方案验证流程包括以下步骤：

第一步，方案提取。从认知AI引擎生成的自然语言回答中提取操作方案的结构化表示。例如，从回答"建议分两步调整：首先将3号闸门开度从1.2m调至1.5m，等待30分钟后再调至1.8m"中提取出：{操作1: (3号闸门, 开度, 1.5m, T+0min), 操作2: (3号闸门, 开度, 1.8m, T+30min)}。

第二步，约束预检查。在提交物理仿真前，先进行快速的约束预检查——各操作是否在设备允许范围内（开度不超过设计最大值、变化速率不超过设备额定速率等）。预检查不合格的方案直接被驳回，无需进行耗时的物理仿真。

第三步，物理仿真验证。将结构化方案提交给物理AI引擎的仿真接口，获取水力响应预测。

第四步，安全包络检查。将仿真结果与安全包络进行对比——所有断面的水位是否在安全范围内、流速是否不超过限值、水位变化速率是否可控。

第五步，结果反馈。如果验证通过，认知AI引擎在回答中附加"该方案已通过水力学仿真验证，各断面水位均在安全范围内"的确认信息；如果验证不通过，认知AI引擎根据失败原因修正方案（如缩小调整幅度或增加过渡时间），然后重新提交验证，最多迭代3次。

**典型案例**

以下是实际运行中的一个方案验证案例。

调度员查询："上游来水增加约15%，能否将4号分水口的分水流量从8增加到10？"

认知AI引擎首先检索相关规程和当前工况，生成初步方案："可以尝试将4号分水口开度从当前的0.6m增至0.75m，预计分水流量从8m³/s增至约10m³/s。"

方案提交物理AI引擎仿真验证。仿真结果显示：分水口下游支渠流量达到预期值，但干渠在分水口下游2km处出现水位下降至控制下限以下0.08m的情况。

安全包络检查不通过。认知AI引擎根据仿真结果修正方案："考虑到下游水位约束，建议分两步执行：先将上游3号闸门开度增大0.15m以补充干渠流量，等待20分钟水位稳定后再增大4号分水口开度至0.75m。"

修正方案重新提交验证。仿真结果显示所有断面水位均在安全范围内。

最终回答："可以将4号分水口分水流量增至10m³/s，但需要分两步操作以确保干渠水位安全：第一步，将3号闸门开度从当前1.35m增至1.50m；第二步，等待20分钟后将4号分水口开度从0.60m增至0.75m。该方案已通过水力学仿真验证，预计干渠最低水位22.12m（安全下限22.00m），有0.12m的安全裕度。建议执行前经值班长确认。"

### 9.7.3 冲突消解实例

在实际运行中，认知AI引擎与物理AI引擎之间偶尔会出现"观点不一致"——认知AI引擎基于规程和经验给出的建议，与物理AI引擎基于数学模型计算的结果不完全吻合。这种冲突需要系统化的消解机制。

项目运行8个月期间记录了37次有意义的双引擎冲突事件（排除因数据延迟等技术原因导致的"假冲突"）。按照第八章8.5节的分类，这些冲突的来源分布为：模型精度差异（15次，40.5%）、时效性差异（12次，32.4%）、知识覆盖差异（7次，18.9%）和假设条件差异（3次，8.1%）。

一个典型的冲突消解案例：

2025年8月某日，调度员询问某渠段在当前工况下能否安全通过35m³/s的流量。认知AI引擎基于规程查询回答"可以，该渠段设计安全通过流量为40m³/s"。但物理AI引擎的仿真结果显示，在当前水温和渠道糙率条件下（夏季水温较高、渠壁生物附着增加了糙率），35m³/s流量会导致局部水位超过安全上限。

冲突消解流程启动。系统首先识别冲突类型为"模型精度差异"——认知AI引擎引用的设计值是基于标准工况的，而物理AI引擎使用的是根据当前实测数据校正的模型参数。根据"安全优先"原则和"物理证据优先于经验规则"原则，系统采纳物理AI引擎的结论，同时向调度员完整解释冲突原因。

最终回答附加了冲突说明："需要注意，虽然该渠段的设计安全通过流量为40m³/s（调度规程§3.2.1），但当前渠道糙率偏高（曼宁系数n=0.018，高于设计值0.014），35m³/s流量下K32+200断面的水位将达到24.42m，超过安全上限24.35m。建议将通过流量控制在33m³/s以内，或优先安排渠道清淤后再提升流量。此结论基于物理仿真模型使用最新实测糙率的计算结果。"

---

## 9.8 人机交互界面设计

技术系统的最终价值通过用户交互来实现。再强大的模型，如果交互界面设计不当，也难以被调度员有效使用。

### 9.8.1 调度员工作台设计

瀚铎大模型的主交互界面被设计为调度员工作台的有机组成部分，而不是一个独立的应用窗口。设计理念是"融入工作流，而非打断工作流"。

界面采用侧栏式布局，默认收起为窄条（宽度48px），显示瀚铎的图标和最近一条未读消息的摘要。调度员点击或使用快捷键（Ctrl+Space）即可展开对话面板（宽度360px），对话面板覆盖在SCADA监控画面的右侧，不影响监控画面的完整显示。

对话面板的上方是快捷操作区，提供5个预置的常用查询按钮："当前工况概要"、"活跃告警分析"、"流量分配建议"、"值班日志草稿"和"规程快速查找"。这些按钮的设计基于对调度员使用习惯的统计分析——约35%的查询属于这五个高频类别，一键直达可以显著提高效率。

对话面板的中间是对话历史区域，显示用户查询和系统回答的完整交互记录。系统回答中涉及的数值（水位、流量等）以可交互的方式呈现——点击数值可以弹出该参数的实时趋势图和历史对比。

对话面板的下方是输入区域，支持文本输入和语音输入。文本输入框支持自动补全——当调度员输入工程设施名称的前几个字时，系统自动弹出候选列表（来自知识图谱中的实体名称）。语音输入针对水利术语进行了优化——ASR（自动语音识别）模型使用了水利术语增强的语言模型，使得"节制闸"、"倒虹吸"等专业术语的识别准确率从通用ASR的约80%提升至96%。

### 9.8.2 多模态信息展示

瀚铎大模型的回答不仅限于文本——根据查询类型和回答内容，系统会自动选择最合适的展示形式。

对于涉及空间分布的信息（如"当前各闸门的开度状态"），系统在文本回答旁边自动生成一个迷你工程示意图，在图上标注各设施的状态值，比纯文本列表更加直观。

对于涉及时间变化的信息（如物理仿真的预测结果），系统生成交互式时间序列图表，调度员可以滑动查看不同时刻的预测值，也可以叠加历史数据进行对比。

对于涉及多步操作的建议，系统生成操作流程卡片（类似于看板），每一步操作显示为一张卡片，包含操作内容、预期效果和注意事项。调度员确认执行某一步后，卡片状态更新为"已执行"，下一步卡片高亮显示。

### 9.8.3 解释性展示

调度员信任系统的前提是理解系统的推理过程。瀚铎大模型为每条回答提供三个层级的解释性信息，调度员可以根据需要逐级展开。

第一级（默认展示）：回答正文，附带来源标注（"根据调度规程§4.3.2"）。

第二级（点击"查看详情"展开）：检索到的原始知识块全文、知识图谱中相关实体的属性卡片、物理仿真结果的详细数据（如果有）。

第三级（点击"查看推理过程"展开）：系统的完整处理流程日志，包括意图分类结果、查询改写内容、各路检索的排序得分、安全审核的检查项和结果。这一级信息主要供系统管理员和技术人员用于调试和优化，普通调度员通常不需要查看。

---

## 9.9 测试与评估

### 9.9.1 测试体系设计

瀚铎水网大模型的测试体系分为四个层级：单元测试、集成测试、场景测试和用户验收测试。

单元测试覆盖各个模块的基本功能：知识图谱的查询正确性、向量检索的召回率、意图分类的准确率、安全规则的触发正确性等。单元测试在每次代码变更后自动运行（CI/CD流水线），确保各模块的基本功能不被回归。

集成测试验证模块间的协作——例如，检索模块返回的知识块是否能被模型正确利用、双引擎接口的数据格式是否正确转换、对话状态管理在多轮交互中是否正确维护等。集成测试每周执行一次。

场景测试是最关键的测试层级。项目组设计了120个测试场景，覆盖9.1.2节定义的五大类使用场景。每个测试场景包括：场景描述（模拟的运行工况和用户操作序列）、预期行为（系统应该执行的处理步骤和给出的回答要点）、评判标准（由三位领域专家按照准确性、完整性、安全性、专业性四个维度独立评分，取平均值）。

用户验收测试（UAT）由实际的调度员在真实运行环境中使用系统，为期一个月。UAT期间收集的数据包括：查询日志、用户反馈（每次交互后的满意度评分和自由文本评论）、任务完成情况记录。

### 9.9.2 领域知识评估结果

使用HydroEval-500测试集对最终部署的模型（经过CPT+SFT+DPO的完整训练流程，配合RAG系统）进行评估。

[表9-3: HydroEval-500评估结果]

| 知识领域 | 基座模型 | +CPT | +SFT | +DPO | +RAG |
|---------|---------|------|------|------|------|
| 水力学基础 | 52.3 | 68.1 | 72.4 | 73.1 | 89.2 |
| 调度管理 | 31.7 | 49.8 | 68.3 | 69.5 | 92.7 |
| 设备知识 | 38.5 | 55.2 | 67.8 | 68.4 | 94.1 |
| 规程理解 | 28.4 | 42.3 | 66.7 | 68.2 | 95.8 |
| 工况推理 | 45.6 | 61.4 | 74.2 | 76.3 | 88.5 |
| **综合** | **41.3** | **58.6** | **71.8** | **73.2** | **92.1** |

注：各行得分为百分制，评分由三位领域专家独立评定后取平均。

几个值得关注的发现：

RAG对"规程理解"和"设备知识"的提升最为显著（从DPO后的约68分提升至95分左右），这是因为这两类知识高度依赖于具体工程的文档信息，RAG能够直接提供最精确的上下文。

"工况推理"在所有阶段的提升都相对平缓（最终88.5分），这是因为工况推理需要的不仅是知识储备，还有综合分析能力——模型需要在理解当前工况、检索相关规程、考虑物理约束和历史经验等多个维度之间进行权衡。

训练各阶段的贡献分析表明，CPT贡献了约18分的基础提升（主要是领域知识的"内化"），SFT贡献了约13分的指令跟随提升（使模型学会按照期望的格式和风格回答），DPO贡献了约1-2分的风格优化，RAG贡献了约19分的最大提升（将外部知识直接注入到推理过程中）。

### 9.9.3 端到端场景测试结果

120个场景测试的结果汇总如下：

[表9-4: 场景测试结果]

| 场景类别 | 场景数 | 通过数 | 通过率 | 平均质量分 |
|---------|-------|-------|--------|-----------|
| 规程查询与解释 | 35 | 33 | 94.3% | 4.3/5 |
| 工况分析与建议 | 30 | 26 | 86.7% | 3.9/5 |
| 异常诊断与处置 | 25 | 21 | 84.0% | 3.8/5 |
| 历史案例检索 | 15 | 13 | 86.7% | 4.0/5 |
| 报告生成 | 15 | 14 | 93.3% | 4.2/5 |
| **总计** | **120** | **107** | **89.2%** | **4.1/5** |

规程查询类场景的通过率最高（94.3%），这与RAG系统在规程文档上的出色检索效果一致。未通过的2个场景涉及跨多份规程的复杂条件组合查询，系统未能完整检索到所有相关条款。

异常诊断类场景的通过率相对较低（84.0%），主要原因是部分异常场景需要结合实时监测数据的趋势分析——当告警涉及多个传感器的关联异常时，系统有时无法正确识别根因。

未通过场景的失败原因分析：知识检索不完整（5个场景）、多步推理错误（4个场景）、双引擎通信超时（2个场景）、安全审核误拦截（2个场景）。

### 9.9.4 用户验收测试结果

UAT在胶东调水工程的三个调度中心进行，参与测试的调度员共15人（其中资深调度员7人、中级调度员5人、初级调度员3人），测试期一个月。

**使用频率统计**

UAT期间系统共处理5,428次查询，日均约181次。使用频率呈现明显的学习曲线——第一周日均约120次（调度员处于探索和学习阶段），第四周日均约230次（调度员已经建立了使用习惯）。

查询类别分布与预期基本一致：规程查询占32.1%、工况分析占24.7%、异常诊断占12.3%、历史检索占8.9%、报告生成占10.5%、其他（包括闲聊和测试性查询）占11.5%。

**满意度评估**

每次交互后系统提供可选的满意度评分（五级量表）。收集到有效评分2,847次（参与率52.4%），平均分4.1分，其中"非常满意"（5分）占28.3%、"满意"（4分）占43.7%、"一般"（3分）占19.1%、"不满意"（2分）占7.2%、"非常不满意"（1分）占1.7%。

不同角色的调度员满意度存在差异：资深调度员平均4.3分（他们主要使用系统查询规程细节和生成报告，这些场景的系统表现最好）、中级调度员平均4.0分、初级调度员平均3.8分（初级调度员更多地提出开放性问题和复杂工况分析需求，系统在这些场景中的表现稍逊）。

**典型用户反馈**

UAT期间收集了大量有价值的用户反馈，以下摘录几条有代表性的意见：

"规程查得比我自己翻文件快多了，特别是那种需要看好几个章节才能确定的条件查询。"——资深调度员

"有时候我问的问题比较模糊，系统会主动确认我具体想问什么，这个设计很好。但偶尔确认的问题问得太啰嗦了，能简洁点就更好了。"——中级调度员

"建议系统能记住我的习惯。我经常关注3号和5号闸门，每次都要重新说明关注哪个闸门比较麻烦。"——值班调度员

"仿真验证功能给了我很大的信心，至少知道我的操作不会出问题。但有时候验证等的时间太长了，紧急情况下可能来不及。"——资深调度员

这些反馈被系统记录和分类，作为后续迭代优化的重要输入。

---

## 9.10 部署运维与持续演进

### 9.10.1 渐进式部署策略

瀚铎水网大模型的部署不是一蹴而就的"大爆炸"上线，而是遵循渐进式策略，分四个阶段推进。

第一阶段（影子模式，2周）：系统接入真实运行数据但不直接面向调度员。调度员在传统系统中正常工作，瀚铎系统在后台对每一次告警和关键操作自动生成分析建议，由技术团队在事后与调度员的实际决策进行对比评估。这一阶段的目的是验证系统在真实数据流下的稳定性和基本正确性。

第二阶段（只读模式，4周）：系统面向调度员开放，但明确标注为"参考工具"，不参与任何操作决策的流程。调度员可以自愿使用系统查询信息和获取建议，但所有操作决策仍然完全由调度员独立做出。这一阶段的目的是让调度员逐步熟悉系统，同时收集用户使用数据和反馈。

第三阶段（辅助模式，持续至今）：系统被纳入调度工作流的辅助环节。对于常规操作，调度员可以直接采纳系统建议（经值班长确认）；对于非常规操作，系统的建议作为参考但不构成执行依据。双引擎的方案验证功能在此阶段正式启用。

第四阶段（协同模式，规划中）：系统深度融入调度决策流程，在预定义的ODD（运行设计域）内可以自动执行部分调度操作（如日常水位调节），调度员转变为监督者角色。这一阶段对应WNAL L3（有条件的高度自主），目前仍在规划和准备中。

### 9.10.2 运行监控与反馈闭环

系统上线后的持续监控是确保长期可靠运行的关键。

**实时监控指标**

运维仪表盘监控以下实时指标：

系统可用性（Availability）：以5分钟为窗口统计系统是否正常响应请求。上线以来的可用性为99.7%（不可用时间主要发生在两次计划内的系统升级期间和一次GPU服务器硬件故障事件中）。

响应时间分布：P50（中位数）约3.2秒、P95约8.7秒、P99约15.3秒。响应时间主要受检索量和是否触发物理仿真验证影响。

错误率：包括系统错误（模型推理失败、服务超时等，约0.3%）和业务错误（回答被安全审核拦截或被用户标记为错误，约0.8%）。

GPU利用率和显存使用率：日常负载下GPU平均利用率约45%，峰值约75%，留有充足的余量应对突发负载。

**反馈闭环机制**

用户反馈通过两个渠道收集：每次交互后的满意度评分（即时反馈）和每月一次的系统使用体验调查（深度反馈）。

即时反馈中被标记为"不满意"或"非常不满意"的交互记录会自动进入"问题队列"，由技术团队在48小时内进行分析和归因。归因结果分为五类：知识缺陷（知识库中信息缺失或过时）、检索失误（相关知识未被检索到）、模型错误（模型推理或生成出错）、系统缺陷（程序Bug或性能问题）和期望差距（系统功能正常但未达到用户预期）。

自上线以来的归因统计显示：知识缺陷占38%、期望差距占27%、检索失误占18%、模型错误占12%、系统缺陷占5%。知识缺陷占比最高说明知识库的持续完善是提升用户满意度的最有效途径。

### 9.10.3 持续学习框架

瀚铎水网大模型不是一个"交付即完成"的静态系统，而是设计了持续学习和演进的框架。

**知识库持续更新**

基于9.3.3节的知识质量保证体系和运行监控反馈，知识库保持月度更新节奏。每月的更新内容包括：新发布的规程和标准的导入、基于用户反馈的知识纠错和补充、过时知识的标注和替换。上线8个月来，知识库共执行了8次月度更新，新增知识块约3,200个，修正约180条错误，标注约45条过时知识。

**模型定期重训练**

随着SFT数据的持续积累（来自运行期间的新标注数据），项目计划每季度对模型进行一次增量微调。增量微调使用新积累的标注数据，在当前模型基础上进行短时间的SFT训练（1个epoch），然后在完整测试集上评估以确保性能不退化。第一次增量微调使用了上线后3个月积累的约2,000条新标注数据，HydroEval-500综合得分从92.1提升至93.5。

**功能迭代规划**

基于UAT和运行期间收集的用户需求，项目组制定了后续功能迭代的路线图：

短期（1-3个月）：优化对话压缩策略以支持更长的多轮对话、增加用户偏好记忆功能（记住调度员常关注的设施和参数）、优化语音交互的准确率和响应速度。

中期（3-6个月）：扩展到其他调水工程的知识库（利用胶东调水的经验加速新工程的部署）、增加调度培训模块（模拟各种工况让新调度员练习决策）、增强跨工程知识迁移能力。

长期（6-12个月）：向WNAL L3协同模式演进（在预定义ODD内支持部分自动调度操作）、开发多工程联合调度的认知支持能力、探索基于运行数据的知识自动发现和规程优化建议功能。

---

## 9.11 经验总结与反思

瀚铎水网大模型项目的实践为水利认知智能的工程化提供了宝贵的经验。本节从成功因素和教训两个方面进行总结。

### 9.11.1 关键成功因素

**领域知识质量是一切的基础。** 项目最终效果的好坏，40%取决于知识库的质量，30%取决于RAG系统的检索效果，20%取决于模型本身的能力，10%取决于其他因素（界面设计、系统性能等）。这个比例可能出乎许多人的预料——在大语言模型的热潮中，人们倾向于把注意力集中在模型本身（选型、训练、参数调优），但实际上在垂直领域应用中，知识库的质量和检索的准确性对最终效果的贡献远大于模型能力的边际提升。项目组在知识库建设上投入了约35%的总工时，事后看来这一投入完全值得。

**双引擎融合提升了系统的可信度。** 在UAT的用户反馈中，"仿真验证"功能是调度员最认可的功能之一。调度员表示，当系统的建议附带了"已通过水力学仿真验证"的标注时，他们对建议的采纳率显著提高。双引擎融合的价值不仅在于提升了回答的准确性（虽然这也很重要），更在于建立了用户对系统的信任——认知AI引擎的"说理"能力与物理AI引擎的"算验"能力相互印证，远比单一引擎更令人信服。

**渐进式部署降低了采纳阻力。** 水利工程领域对新技术的接受通常较为谨慎——这是工程安全文化的合理体现。渐进式部署策略（影子→只读→辅助→协同）允许调度员在低风险的环境下逐步建立对系统的信任和使用习惯。项目的经验表明，从"只读模式"到"辅助模式"的过渡大约需要4-6周——在此期间，调度员从"好奇尝试"逐渐转变为"日常依赖"。

### 9.11.2 教训与不足

**数据质量问题被严重低估。** 项目初期的计划中，数据清洗和知识库建设只分配了总工时的15%，实际执行中膨胀到35%。低估的根本原因是对水利行业文档管理现状缺乏充分认识——不同时期、不同编制人员产出的文档在格式、术语、编码体系上的不一致性远超预期。教训是：在领域大模型项目的规划阶段，必须对数据质量进行充分的预调研，并预留足够的缓冲。

**评估体系需要更早建立。** 项目在开发初期缺乏系统化的评估体系，很多设计决策（如分块大小、检索策略参数等）依赖于开发者的直觉和小规模测试。直到项目中期建立了HydroEval-500和场景测试体系后，才有了量化的评判标准来指导优化方向。如果评估体系更早建立，许多走弯路的迭代可以避免。

**冰期和极端工况的知识覆盖不足。** 系统在常规工况下的表现良好，但在冰期运行等极端工况下的表现明显不如预期。原因是极端工况的运行案例本身就少，能够用于训练和检索的知识储备有限。这个问题的根本解决方案需要依赖持续的案例积累和模型迭代，不是单靠一次性的开发能够完成的。

**用户个性化需求难以满足。** 不同调度员的工作习惯、专业水平和表达方式差异较大，一套统一的系统设置难以满足所有人的需求。UAT反馈中"能不能记住我的习惯"是出现频率最高的改进建议。后续版本已经开始规划用户画像功能，根据调度员的使用历史自动调整回答的详略程度和专业术语密度。

---

## 小结

本章以瀚铎水网大模型的实践为案例，展示了水利认知智能从需求分析到系统部署的完整工程化路径。

在需求分析阶段，项目采用"角色-场景-功能"三层框架，系统梳理了四类用户角色的28个典型使用场景，并建立了涵盖响应性能、知识准确性、安全性和用户体验四个维度的技术指标体系。

在系统设计阶段，项目采用"数据层-知识层-模型层-引擎层-服务层"五层架构，实现了关注点分离和模块化设计。与HydroOS水网操作系统的深度集成使瀚铎大模型成为CHS体系中认知AI引擎的核心实现。"中心+边缘"的混合部署拓扑兼顾了推理性能和高可用性。

在知识体系构建阶段，项目完成了包含28,000个实体和92,000条关系的知识图谱，以及约2000万字的领域语料库。"LLM+人工审核"的半自动化流水线将知识抽取的准确率提升至82%，三道防线的质量保证机制和四步冲突处理流程保障了知识库的长期可靠性。

在模型训练阶段，项目选定Qwen2.5-72B作为基座，经过CPT（领域困惑度从18.7降至7.2）、SFT（HydroEval-500从58.6提升至71.8）和DPO（专家偏好率67.2%）的完整训练流程。配合RAG系统后综合得分达到92.1分。

在RAG系统建设阶段，项目实现了"语义+关键词+知识图谱"三路混合检索架构和动态权重融合策略，Top-5命中率达91.6%。查询改写和多模态上下文构建进一步提升了端到端的回答质量。

在引擎集成阶段，项目实现了完整的认知AI引擎功能，包括两级意图分类（准确率94.2%/87.6%）、差异化任务路由、对话状态管理和三层安全审核机制。双引擎融合的方案验证闭环和冲突消解机制是系统可信度的重要保障。

在部署运维阶段，渐进式部署策略（影子→只读→辅助→协同）降低了用户采纳阻力。运行监控和反馈闭环确保了系统的持续改进。上线8个月来，系统累计服务超过40,000次交互，用户满意度平均4.1/5，场景测试通过率89.2%。

瀚铎水网大模型的实践表明，水利认知智能的工程化不仅是一个技术问题，更是一个系统工程问题。领域知识的质量、多技术的有机融合、用户信任的渐进建立——这些"软因素"对项目成功的贡献不亚于模型和算法本身。

---

## 习题

### 基础题

1. 简述瀚铎水网大模型的五层架构，并说明各层之间的主要接口。为什么采用分层架构而不是端到端的一体化设计？

2. 在知识图谱构建实践中，"LLM+人工审核"的半自动化流水线的各步骤是什么？大模型辅助抽取的准确率约为多少？如何处理抽取结果中的错误？

3. 解释三路混合检索（语义检索+关键词检索+知识图谱查询）中加权互排序融合（Weighted RRF）的公式。为什么不同查询类型需要不同的权重配置？

### 应用题

4. 假设你负责将瀚铎水网大模型部署到一个新的调水工程。该工程的规模是胶东调水工程的一半，但拥有完善的SCADA系统和规范的调度规程文档。请设计一个为期6个月的部署计划，包括知识库建设（估算工作量）、模型适配（是否需要重新CPT/SFT？）、部署策略和测试方案。说明哪些组件可以直接复用，哪些需要重新开发。

5. 某次运行中，调度员查询"上游来水突增30%，如何调整闸门？"。请详细描述该查询在瀚铎系统中的完整处理流程：从意图识别到最终回答呈现的每一个步骤，特别说明双引擎如何协作。如果物理AI引擎的仿真结果表明认知AI引擎的初始方案不可行，系统如何处理？

6. 瀚铎项目的HydroEval-500评估结果（表9-3）显示，"工况推理"类题目的得分在所有训练阶段中提升最为平缓，RAG的加持也相对有限。请分析可能的原因，并提出至少两种提升"工况推理"能力的技术方案。

### 思考题

7. 本章的经验总结指出"40%取决于知识库质量，30%取决于RAG效果，20%取决于模型能力"。如果模型能力发展到GPT-6级别（假设其领域知识理解能力大幅提升），这个比例会如何变化？知识库建设是否会变得不那么重要？RAG是否会被淘汰？请从架构和工程的角度分析。

8. 瀚铎水网大模型的安全审核机制采用了"宁可误报、不可漏报"的原则。在实际运行中，这意味着一些安全的操作建议也会被拦截，需要人工确认。如果误拦截率过高，可能会降低调度员对系统的信任（"狼来了"效应）。请讨论如何在安全性和可用性之间取得平衡，并设计一个自适应调整拦截阈值的机制。

9. 瀚铎项目目前仅部署在胶东调水工程。如果要将其推广到中国的多个调水工程乃至国际水利项目，最大的挑战是什么？请从知识迁移、模型适配、文化差异和制度规范四个角度分析。

---

## 拓展阅读

1. **Lewis, P., Perez, E., Piktus, A., et al. (2020).** "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." *NeurIPS 2020*. — RAG方法的奠基性论文，提出了将检索与生成相结合的框架，为瀚铎项目的RAG系统设计提供了理论基础。

2. **Rafailov, R., Sharma, A., Mitchell, E., et al. (2023).** "Direct Preference Optimization: Your Language Model is Secretly a Reward Model." *NeurIPS 2023*. — DPO算法的原始论文，提供了一种不需要显式奖励模型的偏好优化方法，瀚铎项目在训练流程的最后阶段采用了该方法。

3. **Gao, Y., Xiong, Y., Gao, X., et al. (2024).** "Retrieval-Augmented Generation for Large Language Models: A Survey." *arXiv:2312.10997*. — RAG技术的全面综述，覆盖了检索、增强和生成三个阶段的最新进展，对设计和优化RAG系统有重要参考价值。

4. **Lei, X. et al. (2025a).** "Cybernetics of Hydro Systems: Principles and Theoretical Framework." *南水北调与水利科技（中英文）*, DOI: 10.13476/j.cnki.nsbdqk.2025.0078. — CHS理论框架，为瀚铎水网大模型在水系统控制论体系中的定位提供了理论依据。

5. **Lei, X. et al. (2025b).** "Architecture of Autonomous Intelligent Water Networks." *南水北调与水利科技（中英文）*, DOI: 10.13476/j.cnki.nsbdqk.2025.0079. — 自主智能水网架构论文，详细阐述了认知AI引擎在HydroOS中的定位和接口设计，是瀚铎项目系统架构设计的重要参考。

6. **Bai, J., Bai, S., Chu, Y., et al. (2023).** "Qwen Technical Report." *arXiv:2309.16609*. — Qwen模型系列的技术报告，瀚铎项目选用Qwen2.5-72B作为基座模型，该报告提供了模型架构和预训练方法的详细说明。

7. **Xiao, S., Liu, Z., Zhang, P., & Muennighoff, N. (2024).** "C-Pack: Packaged Resources to Advance General Chinese Embedding." *arXiv:2309.07597*. — BGE嵌入模型的技术报告，瀚铎项目的向量检索和重排序模型均基于BGE系列模型微调，该报告对理解基线模型的能力和局限有参考价值。
