<!-- 变更日志
v1 2026-02-19: 初稿
-->

# 第七章 人机协同决策与对话调度

---

## 学习目标

完成本章后，读者应能够：

1. 理解人机协同的理论基础，掌握自动化层级（LOA）模型和人机信任动态模型在水利调度中的应用；
2. 设计水网调度中的决策权限分配方案，明确在不同WNAL等级和不同工况下人与AI的职责边界；
3. 设计面向调度场景的多轮对话交互策略，包括意图识别、上下文管理、澄清机制和对话状态跟踪；
4. 构建认知AI引擎的解释性机制，使其推理过程对调度员透明可审；
5. 制定调度员与AI系统协同工作的培训方案，建立恰当的信任校准机制。

---

## 7.1 从"读屏幕"到"对话"：调度模式的范式转变

### 7.1.1 一个典型的对话调度场景

2026年7月15日凌晨3:17，山东省胶东调水工程调度中心。值班调度员张工被一连串告警惊醒——上游连续暴雨使得黄水东调干渠来水量在过去两小时内从设计流量的80%飙升至130%。传统SCADA屏幕上，十几个监控点的水位曲线同时飘红，六座节制闸的状态参数密密麻麻地排列着。张工需要在短时间内做出判断：哪些闸门需要调整？调整多少？上下游的联动效应如何？沿线分水口是否需要临时关闭？

在传统模式下，张工需要同时监控多个屏幕、翻阅调度规程、心算水力传播时间、电话联络上下游管理所——这一系列操作的认知负荷极高，尤其在凌晨注意力下降的时段。

现在，张工转向认知AI引擎的对话终端：

> **张工**：当前干渠来水量超设计130%，上游3个监测站水位超警戒，请分析当前工况并给出建议。
>
> **认知AI引擎**：收到。当前工况分析如下：
> - 黄水东调干渠桩号K0+000至K45+800段来水量均值为65.3 m³/s（设计50 m³/s），超设计30.6%
> - 3号、5号、7号监测站水位分别超警戒线0.12m、0.23m、0.08m
> - 根据水力模型推演，洪峰将在约2.5小时后到达K80+000节制闸
> - 参照《胶东调水工程汛期调度规程》第4.3条，当前属于"Ⅲ级应急响应"启动条件
>
> **建议方案**：
> 1. 立即开启K45+800分洪闸至50%开度，分洪流量约12 m³/s
> 2. K80+000节制闸预降0.3m水位，为洪峰过境腾出调蓄空间
> 3. 通知下游K120+000管理所做好接水准备
>
> 方案置信度：**中高**（85%）。物理AI引擎已完成水力仿真验证，预计方案执行后各断面水位均在安全包络内。如需查看仿真结果详情，请说"展示仿真"。
>
> **张工**：5号站水位上升速度如何？分洪闸开到50%够不够？
>
> **认知AI引擎**：5号站过去1小时水位上升速率为0.11 m/h，呈加速趋势。物理AI引擎的30分钟预测显示，若分洪闸开度50%，5号站水位将在1.5小时后回落至警戒线以下；若仅开30%则需约3小时。50%开度留有约15%的安全裕度。建议维持50%方案。
>
> **张工**：好的，执行方案1和方案2。方案3我来电话通知下游。

这段对话展示了一种全新的调度模式——**对话调度（Conversational Dispatching）**。调度员不再需要独自面对密密麻麻的数据屏幕、凭记忆翻找规程条款、心算水力参数，而是通过自然语言与认知AI引擎交互，获得融合了实时数据、模型计算、规程知识和历史经验的综合决策支持。

### 7.1.2 调度模式演进的三个阶段

回顾水利调度的技术发展，可以清晰地划分出三个阶段：

**第一阶段：手动调度（Manual Dispatching）**。调度员依靠电话、纸质记录和个人经验进行决策。信息获取慢、决策周期长、严重依赖个人经验。这个阶段对应WNAL L0-L1。

**第二阶段：数字化调度（Digital Dispatching）**。SCADA系统提供实时数据监控，计算机辅助系统提供优化计算结果，调度员通过屏幕获取信息、通过键鼠下达指令。信息获取速度大幅提升，但调度员的认知负荷随系统复杂度同步增长——更多的屏幕、更多的参数、更多的告警。这个阶段对应WNAL L1-L2。

**第三阶段：对话调度（Conversational Dispatching）**。认知AI引擎作为调度员的"智能副驾驶"，通过自然语言对话提供情境感知的决策支持。调度员从"信息搜集者"转变为"决策确认者"，认知负荷显著降低，决策质量和响应速度同时提升。这个阶段对应WNAL L2-L3。

三个阶段的核心差异可以从信息流向来理解：手动调度是"人找信息"，数字化调度是"屏幕呈现信息、人筛选信息"，对话调度是"AI理解需求、主动推送决策相关信息"。

### 7.1.3 对话调度并非全自动调度

一个重要的澄清：对话调度不是要取代调度员，而是要增强调度员。在CHS框架的WNAL分级体系中（参见T1-CN第四章），对话调度主要对应L2（条件自主）和L3（高度自主）阶段——人类调度员始终是最终决策者，认知AI引擎是"建议者"而非"决定者"。

这个定位源于两个基本判断。第一，水利调度涉及公共安全和不可逆后果，在可预见的未来内需要人类的最终判断。第二，当前AI技术在处理极端罕见工况（长尾事件）时的可靠性尚不足以支撑完全自主决策。

因此，本章的核心命题是：如何设计人与AI之间的协同机制，使这种"人类决策+AI辅助"的模式达到最优效果？这涉及信任、透明度、权限分配、对话设计等一系列交叉问题。

---

## 7.2 人机协同的理论基础

### 7.2.1 自动化层级模型

人机协同研究的经典框架是Sheridan和Verplank（1978）提出的**自动化层级（Levels of Automation, LOA）**模型。该模型将人机分工描述为一个从"完全人工"到"完全自动"的连续谱：

| LOA | 描述 | 人的角色 | 机器的角色 | 水利调度对应 |
|-----|------|---------|-----------|-------------|
| 1 | 计算机不提供帮助 | 全部决策 | 无 | 纸质调度 |
| 2 | 计算机提供一组可选方案 | 选择方案 | 方案生成 | SCADA+优化计算 |
| 3 | 计算机推荐一个方案 | 批准/否决 | 方案生成+推荐 | 认知AI建议 |
| 4 | 计算机执行方案，人可否决 | 监控+否决 | 自动执行+等待否决 | WNAL L3条件自主 |
| 5 | 计算机执行，事后通知人 | 事后审查 | 自动执行 | WNAL L4部分场景 |
| 6-10 | 逐步减少人的参与 | 被动观察→无 | 全自动 | WNAL L4-L5 |

Parasuraman, Sheridan和Wickens（2000）进一步将LOA细化为四个功能维度：**信息获取（Information Acquisition）**、**信息分析（Information Analysis）**、**决策选择（Decision Selection）**和**动作执行（Action Implementation）**。每个维度可以独立设置不同的自动化层级，这为水利调度的灵活分工提供了理论基础。

例如，在当前对话调度的典型配置中：信息获取的自动化程度很高（SCADA自动采集），信息分析的自动化程度中高（认知AI引擎自动进行工况研判），决策选择的自动化程度中等（AI推荐方案但人做最终选择），动作执行的自动化程度中等（常规操作自动化，非常规操作人工确认）。

### 7.2.2 情境感知与决策偏差

水利调度是典型的**情境感知（Situation Awareness, SA）**密集型任务。Endsley（1995）将情境感知分为三个层次：

**SA Level 1——感知（Perception）**：感知环境中的关键要素。对应水利调度中的"看到水位、流量等实时数据"。

**SA Level 2——理解（Comprehension）**：理解感知信息的含义。对应"判断当前工况属于何种类型、是否超出安全包络"。

**SA Level 3——预测（Projection）**：预测系统未来状态。对应"推断洪峰何时到达下游、闸门调整后水位如何变化"。

认知AI引擎在三个层次上都能提供支持：在SA-L1层自动聚合多源数据，在SA-L2层提供工况分类和规程匹配，在SA-L3层通过物理AI引擎的仿真预测提供前瞻性信息。

然而，引入AI辅助也可能产生新的问题。认知心理学研究揭示了多种与自动化相关的决策偏差：

**自动化偏信（Automation Complacency）**：过度依赖自动化系统，减少人工监控和交叉验证。当AI系统大部分时间工作良好时，调度员可能放松警惕，在AI出错的罕见情况下未能及时发现和纠正。

**自动化惊吓（Automation Surprise）**：当自动化系统的行为超出操作员预期时产生的困惑和不知所措。如果调度员不理解AI建议的推理过程，当AI给出意外建议时可能陷入"它为什么这样建议？"的困惑。

**技能退化（Skill Degradation）**：长期依赖自动化可能导致人工操作技能退化，使得在系统故障时的人工接管变得困难。

**注意力隧道化（Attentional Tunneling）**：过度关注AI推荐的方案而忽略AI未涉及的其他重要因素。

这些偏差的存在意味着，人机协同系统的设计不仅要考虑"如何让AI更好地辅助人"，还要考虑"如何防止AI辅助反而削弱人的决策能力"。这是对话调度系统设计的核心挑战之一。

### 7.2.3 人机信任动态模型

信任是人机协同的核心变量。Lee和See（2004）提出了一个被广泛引用的**人机信任框架**，将信任定义为"在不确定和脆弱性存在的情况下，代理（agent）将帮助实现个体目标的态度"。他们将信任的基础分为三个维度：

**性能信任（Performance-based Trust）**：基于系统的历史表现——"它过去做得好不好？"这是最直观的信任来源。在水利调度中，如果认知AI引擎过去的建议准确率高、失误率低，调度员自然会更信任它。

**过程信任（Process-based Trust）**：基于系统运作过程的可理解性——"它是怎么得出这个结论的？"当调度员能理解AI的推理逻辑时，信任程度更高。这也是可解释性（Explainability）之所以重要的原因。

**目的信任（Purpose-based Trust）**：基于系统设计目的的认同——"它的目标和我一致吗？"当调度员相信AI系统的优化目标与自己的调度目标一致时，信任更容易建立。

信任并非静态的，而是在每次交互中动态演化的。一个简化的信任动态模型可以表达为：

$$T_{t+1} = T_t + \alpha \cdot (O_t - E_t)$$

其中 $T_t$ 是第 $t$ 次交互时的信任水平，$O_t$ 是观测到的系统表现（实际结果），$E_t$ 是调度员的期望，$\alpha$ 是学习率（反映调度员更新信任的速度）。当实际表现超出期望时信任增加，反之则下降。

实际的信任动态远比这个线性模型复杂——信任的建立通常是缓慢渐进的，而信任的破坏往往是突然剧烈的（一次严重失误可能摧毁长期建立的信任）。这种不对称性在系统设计中必须充分考虑。

### 7.2.4 恰当信任：不多不少

信任校准（Trust Calibration）的目标是使调度员对AI的信任程度与AI的实际能力相匹配。Lee和See（2004）指出了两种失配状态：

**过度信任（Overtrust / Misuse）**：信任程度超过系统的实际可靠性。表现为盲目接受AI建议、减少人工检查。在水利调度中，过度信任可能导致在AI给出错误建议时未能及时纠正，酿成工程事故。

**信任不足（Undertrust / Disuse）**：信任程度低于系统的实际可靠性。表现为忽略AI建议、坚持纯人工决策。在水利调度中，信任不足意味着投入大量资源建设的智能系统形同虚设。

恰当信任（Appropriate Trust）是两者之间的平衡状态——调度员在AI擅长的领域充分利用AI能力，在AI能力边界外保持独立判断。实现这种恰当信任需要多方面的系统设计支持：

**置信度展示**：每个建议附带置信度评分，让调度员知道AI对自身判断的确信程度。低置信度时调度员自然会更加审慎。

**推理透明**：展示AI得出结论的关键推理步骤和依据，让调度员能够独立评估推理过程的合理性。

**能力边界标注**：明确告知调度员AI在哪些工况下表现可靠、在哪些工况下可靠性下降（如极端罕见工况、训练数据未覆盖的场景）。

**错误经历教育**：在培训中展示AI曾经犯过的典型错误，帮助调度员建立对AI能力局限性的现实认知。

---

## 7.3 决策权限分配框架

### 7.3.1 基于WNAL的权限分级

CHS框架的WNAL（水网自主等级）分级体系为人机权限分配提供了顶层框架（参见T1-CN第四章）。在每个WNAL等级下，认知AI引擎的决策权限有明确边界：

**WNAL L0（手动）**：认知AI引擎仅作为知识查询工具。调度员主动提问，AI被动回答。AI不主动推送信息，不生成建议方案。决策完全由人类完成。

**WNAL L1（辅助）**：认知AI引擎增加告警解释和信息聚合功能。当SCADA产生告警时，AI自动附加告警原因分析和相关规程条款。AI仍不主动生成调度建议。

**WNAL L2（条件自主）**：认知AI引擎可以主动生成调度建议方案，但所有方案必须经调度员确认后才能执行。AI建议具有"建议"性质而非"指令"性质。这是当前对话调度系统的主要目标等级。

**WNAL L3（高度自主）**：在预定义的"正常运行设计域（ODD）"内，认知AI引擎的建议可以自动执行（调度员有否决权），但在ODD边界外仍需人工确认。AI具有"默认执行，人可否决"的权限。

**WNAL L4-L5（完全自主）**：认知AI引擎参与全自主决策闭环。人类角色转变为系统监管者和规则制定者。这是远期目标，当前技术条件下尚不适用于关键基础设施。

### 7.3.2 四维权限矩阵

借鉴Parasuraman等人（2000）的四维LOA框架，我们为水利对话调度设计了**四维权限矩阵**：

| 功能维度 | L0手动 | L1辅助 | L2条件自主 | L3高度自主 |
|---------|-------|-------|-----------|-----------|
| **信息获取** | 人工查询 | 自动采集+人工补充 | 自动采集+自动聚合 | 全自动+异常检测 |
| **信息分析** | 人工分析 | AI辅助分类 | AI主动研判+人审核 | AI自主研判 |
| **决策选择** | 人工决策 | 人决策+AI参考 | AI推荐+人确认 | AI默认+人否决 |
| **动作执行** | 人工操作 | 人工操作 | 常规自动+异常人工 | ODD内自动 |

以WNAL L2为例，信息获取和信息分析的自动化程度已经相当高（AI自动采集数据并进行工况研判），但决策选择仍然以人为主（AI推荐方案，人类确认），动作执行则是混合模式（常规操作可以自动化，非常规操作需人工确认）。

### 7.3.3 工况驱动的动态权限调整

权限分配不是一成不变的。不同工况下，AI系统的可靠性不同，因此权限应该动态调整。我们提出**工况-置信度-权限**三级联动机制：

**正常工况（Green Zone）**：系统运行在安全包络内，各参数在设计范围内。AI系统在此区间的训练数据充足、表现稳定。此时AI可以拥有较高的权限（如自动执行常规调整）。

**预警工况（Yellow Zone）**：部分参数接近安全包络边界，但尚未超出。AI系统的可靠性开始下降（边界区域的训练样本较少）。此时应自动收紧权限——所有建议必须经调度员确认。

**应急工况（Red Zone）**：参数超出安全包络或出现未预见的异常组合。AI系统进入低置信度区域。此时应进一步收紧权限——AI仅提供参考信息，不生成执行方案；同时向调度员明确提示"当前工况超出AI可靠决策范围，请依据专业判断和应急预案操作"。

这种动态权限机制可以用一个简单的规则来表达：

$$L_{effective} = \min(L_{WNAL}, L_{confidence})$$

其中 $L_{WNAL}$ 是系统配置的WNAL等级对应的最大权限，$L_{confidence}$ 是基于当前工况置信度的权限上限。系统的有效权限取两者的较小值。这意味着即使系统配置为L3，在低置信度工况下也会自动降级到L2甚至L1运行。

### 7.3.4 关键决策的"四眼原则"

对于涉及以下场景的决策，无论WNAL等级如何，都必须执行**"四眼原则"（Four-Eyes Principle）**——至少两个独立来源确认后才能执行：

**不可逆操作**：大型闸门的紧急全关或全开、泵站的紧急停机等操作一旦执行可能造成不可逆的水力瞬变。AI建议+调度员确认+值班长复核。

**跨区域联动**：涉及多个管理区段的联合调度操作，影响范围超出单个调度员的管辖区域。需要相关区段调度员的协同确认。

**超设计工况**：流量超过设计标准、水位超过校核标准等极端工况。应启动应急预案，AI系统自动降级为信息提供者角色。

**安全相关操作**：涉及大坝安全、防洪安全等关键安全操作。遵循现有的安全管理制度和审批流程，AI建议仅作为参考输入之一。

### 7.3.5 权限配置的工程实现

在HydroOS中，权限配置通过一个声明式的**权限策略文件（Authorization Policy File）**来管理：

```yaml
# HydroOS 认知AI引擎权限策略
version: "2.0"
wnal_level: L2  # 系统基准WNAL等级

# 信息维度权限
information:
  acquisition: auto       # 自动采集
  analysis: ai_with_review # AI分析+人审核
  
# 决策维度权限
decision:
  normal_ops:              # 正常工况
    mode: ai_recommend     # AI推荐+人确认
    auto_execute_if:       # 满足以下条件可自动执行
      - confidence >= 0.95
      - impact_level <= "minor"
      - within_odd: true
  abnormal_ops:            # 异常工况
    mode: human_primary    # 人主导+AI参考
    ai_role: info_provider # AI仅提供信息
    
# 动作维度权限
action:
  gate_adjustment:
    max_auto_change: 10%   # 单次自动调整幅度上限
    require_confirm_above: 20%  # 超过20%必须人工确认
  pump_control:
    auto_start: false      # 泵站启动不允许自动执行
    auto_stop_emergency: true  # 紧急停机允许自动触发

# 四眼原则触发条件
four_eyes:
  triggers:
    - irreversible_action: true
    - cross_region: true
    - beyond_design_capacity: true
    - safety_critical: true
  required_approvals: 2
```

这种声明式配置的优势在于：权限策略与代码逻辑分离，便于管理者根据工程实际情况调整，无需修改程序代码；审计时只需检查策略文件即可了解权限设置；不同工程可以使用不同的策略文件适应各自的管理需求。

---

## 7.4 对话交互设计

### 7.4.1 水利调度对话的特殊性

水利调度对话与通用聊天机器人有本质区别。理解这些区别是设计有效对话系统的前提：

**实时性约束**：调度对话往往发生在工况快速变化的场景中，对话的响应时间直接影响决策时效。调度员不会像日常聊天那样等待30秒的回复——在汛期应急场景中，每多延迟一分钟，洪峰就多推进一段距离。系统的端到端响应时间目标是P95 < 5秒（常规查询）和P95 < 10秒（复杂分析）。

**准确性要求**：调度对话中的每一个数据、每一条建议都可能影响工程安全和社会公共利益。容错空间极小，AI系统"幻觉"（Hallucination）的后果可能是灾难性的。这要求对话系统在不确定时明确表达不确定，而非生成看似合理但实际错误的回答。

**专业术语密度**：水利调度涉及大量专业术语、工程代号和行业缩写。"K45+800分洪闸"、"Ⅲ级应急响应"、"安全包络黄区"——这些表达在水利调度语境中有精确含义，对话系统必须准确识别和使用。

**多方协同**：实际调度往往涉及多个调度员、多个管理区段的协同。对话系统可能需要支持多人同时交互，并维护各方的信息一致性。

**操作闭环**：调度对话的最终目的不是获取信息，而是执行操作。对话系统需要能够将自然语言指令转化为结构化的控制参数，并跟踪操作的执行状态。

### 7.4.2 意图分类体系

水利调度对话中调度员的意图可以归纳为以下类别。准确的意图识别是对话系统正确响应的前提：

**查询类意图（Query Intent）**

- 实时数据查询："5号站当前水位是多少？"
- 历史数据查询："昨天下午3点的来水量是多少？"
- 规程查询："Ⅲ级应急响应的启动条件是什么？"
- 设备状态查询："K80节制闸当前开度和设备状态？"

**分析类意图（Analysis Intent）**

- 工况研判："当前工况属于什么级别？"
- 趋势分析："上游来水量的变化趋势如何？"
- 原因分析："3号站水位异常升高的可能原因是什么？"
- 影响评估："如果关闭分水口，下游用户的影响范围有多大？"

**建议类意图（Recommendation Intent）**

- 方案请求："来水超标，请给出调度建议。"
- 方案比较："方案A和方案B哪个更优？"
- 方案优化："能否在减少弃水的前提下保证水位安全？"
- 应急方案："突发设备故障，紧急处置方案是什么？"

**执行类意图（Execution Intent）**

- 方案确认："执行方案1。"
- 参数调整："把分洪闸开度改为60%。"
- 操作撤销："取消刚才的闸门调整指令。"
- 状态查询："刚才的指令执行到什么程度了？"

**元对话意图（Meta-Dialogue Intent）**

- 解释请求："为什么建议开50%而不是30%？"
- 置信度询问："你对这个建议的把握有多大？"
- 数据来源确认："这个数据是来自SCADA实时还是历史统计？"
- 对话控制："回到刚才讨论的应急方案。"

### 7.4.3 多轮对话状态管理

水利调度对话通常是多轮的——一次调度决策可能涉及十几轮对话交互。有效的多轮对话管理需要维护丰富的对话状态：

**对话状态模型**

我们采用一个扩展的对话状态跟踪（Dialogue State Tracking, DST）模型。对话状态 $S_t$ 在每个对话轮次 $t$ 更新，包含以下字段：

```
DialogueState = {
  session_id: str,            # 对话会话ID
  turn_count: int,            # 当前轮次
  current_intent: Intent,     # 当前意图
  topic_stack: [Topic],       # 话题栈（支持话题切换和回溯）
  
  # 调度上下文
  active_scenario: Scenario,  # 当前调度场景（正常/预警/应急）
  monitored_stations: [Station],  # 关注的监测站列表
  pending_actions: [Action],  # 待执行的操作列表
  executed_actions: [Action], # 已执行的操作列表
  
  # 方案上下文
  proposed_plans: [Plan],     # 已提出的方案列表
  selected_plan: Plan,        # 已选择的方案
  plan_status: PlanStatus,    # 方案执行状态
  
  # 数据上下文
  referenced_data: [DataRef], # 对话中引用过的数据
  time_context: TimeRange,    # 时间上下文（当前关注的时间范围）
  
  # 信任上下文
  ai_confidence: float,       # 当前AI置信度
  user_agreement_history: [bool],  # 用户同意/否决AI建议的历史
}
```

**话题栈管理**

调度对话中经常出现话题切换——调度员可能在讨论A方案时突然问一个关于B区域的问题，之后又回到A方案。话题栈用于追踪这种切换：

> **张工**：K80闸门的调整方案是什么？ *[话题入栈: K80闸门调整]*
>
> **AI**：建议K80闸门开度从30%提升至50%...
>
> **张工**：等一下，K120那边现在什么情况？ *[话题入栈: K120现状]*
>
> **AI**：K120当前水位4.52m，流量38.2 m³/s，运行正常...
>
> **张工**：好的，回到K80的方案，50%会不会太大了？ *[话题出栈，回到K80]*
>
> **AI**：关于K80开50%的方案，考虑到上游来水趋势...

话题栈的正确管理确保了对话的连贯性——当调度员说"回到刚才的方案"时，系统知道应该恢复哪个上下文。

**共指消解**

调度对话中充斥着代词和省略——"那个闸门"、"把它调高一点"、"和刚才一样的操作"。共指消解（Coreference Resolution）在水利调度语境中尤为重要，因为指代错误可能导致操作对象错误。

系统采用**最近实体优先+类型约束**的策略进行共指消解：

- "那个闸门" → 对话中最近提及的闸门实体
- "上游" → 相对于当前讨论焦点的上游
- "调高一点" → 在当前操作对象上增加调整量（需进一步澄清具体数值）

对于可能引起歧义的指代，系统应主动请求澄清而非猜测：

> **张工**：把它开大一点。
>
> **AI**：确认一下——您是指K80+000节制闸的开度吗？"开大一点"建议增加10%（从30%到40%），还是其他幅度？

### 7.4.4 澄清策略设计

在水利调度这种高安全性场景中，"宁可多问一句，不可猜错操作"是基本原则。系统的澄清策略遵循以下规则：

**必须澄清的场景**

- 操作对象不明确："把闸门开大"（哪个闸门？）
- 操作幅度不明确："调高一点"（调高多少？）
- 意图二义性："关于K80的情况"（是查询数据还是请求建议？）
- 安全敏感操作："执行方案"（确认具体方案编号和参数）

**无需澄清的场景**

- 上下文明确的引用：对话中只讨论了一个闸门，"把它开大"的指代是唯一的
- 标准操作的标准参数：查询类操作不涉及安全风险
- 调度员的明确指令：参数完整、对象明确的直接指令

**澄清方式的选择**

- **选项式澄清**：当可能的选项有限时，列出选项供调度员选择。"您是指：(A) K80+000节制闸 (B) K120+500分洪闸？"
- **确认式澄清**：当系统有较高置信度的推断时，附带确认请求。"理解为将K80闸门开度提升10%至40%，确认执行？"
- **开放式澄清**：当缺乏足够信息推断时，请求补充信息。"请说明目标闸门的桩号和期望的调整幅度。"

### 7.4.5 对话策略引擎

综合以上设计，对话策略引擎的处理流程如下：

```
输入: 用户话语 U_t, 对话状态 S_t

Step 1: 语义解析
  - 意图分类 → intent ∈ {query, analysis, recommendation, execution, meta}
  - 实体提取 → entities = {station, gate, parameter, value, time, ...}
  - 共指消解 → resolved_entities

Step 2: 状态更新
  - 更新话题栈（新话题/延续话题/回溯话题）
  - 更新调度上下文（监测站、方案、操作）
  - 更新数据上下文（引用的数据、时间范围）

Step 3: 澄清检查
  IF 操作类意图 AND (对象模糊 OR 参数缺失 OR 安全敏感):
    → 生成澄清请求
  ELSE:
    → 继续处理

Step 4: 权限检查
  - 检查当前WNAL权限配置
  - 检查工况-置信度-权限联动
  IF 权限不足:
    → 说明权限限制，提供可行的替代操作
  ELSE:
    → 继续处理

Step 5: 响应生成
  CASE intent:
    query → 检索数据/知识，生成回答
    analysis → 调用分析模块，生成研判结论
    recommendation → 调用方案生成模块，生成建议
    execution → 生成执行确认请求，转发控制指令
    meta → 调用解释模块或对话管理功能

Step 6: 安全审核
  - 三层安全检查（规则→LLM自检→数值校验）
  - 安全审计日志记录

输出: 系统回复 R_t, 更新后的对话状态 S_{t+1}
```

---

## 7.5 主动信息推送与态势增强

### 7.5.1 从被动回答到主动推送

传统的人机交互是"一问一答"模式——用户提问，系统回答。但在水利调度场景中，认知AI引擎不应仅仅被动等待调度员提问，还应具备**主动信息推送（Proactive Information Push）**能力。这是因为：

第一，调度员可能因注意力分散而遗漏重要信息。尤其在多任务并行或长时间值班时，调度员可能未注意到某个监测站的水位正在缓慢上升。

第二，某些关键信息的时效性很强，延迟推送可能丧失最佳响应窗口。例如，上游降雨预报变化后，如果不及时通知调度员，可能错过提前预降水位的最佳时机。

第三，AI系统通过持续监控全网状态，能够发现调度员单凭人工监控难以察觉的异常模式（如多个参数的微弱关联变化）。

### 7.5.2 推送优先级分级

并非所有信息都值得主动推送——过多的推送会造成"信息轰炸"，反而降低调度员的注意力。我们设计了四级推送优先级：

**P0级——紧急（Critical）**：涉及安全包络突破、设备故障、人身安全等紧急事项。推送方式为立即中断当前对话，声光告警同步。示例："K45+800水位已突破安全包络上限！当前5.82m，上限5.70m，请立即处置。"

**P1级——重要（Important）**：涉及工况变化趋势、预警阈值接近、气象预报更新等需要调度员及时知晓的信息。推送方式为在对话界面显著提示，但不中断当前对话。示例："提醒：上游3小时降雨预报已更新，预计来水量将从当前45 m³/s增至58 m³/s（+29%），预计2小时后到达。"

**P2级——通知（Notice）**：涉及已下达指令的执行进度、定期状态汇总、计划性操作提醒等。推送方式为在消息列表中标记，调度员可在方便时查看。示例："通知：K80闸门开度已从30%调整至50%，调整完成时间14:35，当前运行正常。"

**P3级——信息（Info）**：涉及统计报表、知识库更新、系统状态等低紧急度信息。推送方式为仅记录在消息日志中，不主动弹窗。

### 7.5.3 智能推送时机选择

除了推送优先级，推送时机的选择也至关重要。在不恰当的时机推送非紧急信息可能干扰调度员的当前操作。系统应考虑以下因素：

**对话间隙推送**：对于P1-P2级信息，优先在对话的自然间隙（调度员完成一轮操作、等待执行结果等）推送，避免中断调度员的思考链。

**聚合推送**：多条同类信息聚合为一条推送。例如，不是分别推送"1号站水位上升0.05m"、"2号站水位上升0.03m"、"3号站水位上升0.07m"，而是聚合为"干渠上游段（1-3号站）水位整体上升0.03-0.07m，均值+0.05m"。

**上下文关联推送**：当推送信息与调度员当前对话话题相关时，可以自然地融入对话。例如，当调度员正在讨论K80闸门调整方案时，系统发现上游来水预报发生变化，可以在回答中自然地引入这一新信息："关于K80闸门的调整建议——需要提醒您注意，上游3小时降雨预报刚刚更新，建议将调整幅度从之前建议的50%修正为55%。"

### 7.5.4 告警增强

传统SCADA系统的告警往往是简单的阈值告警——"水位超过X值"。认知AI引擎可以为告警添加丰富的上下文信息，帮助调度员快速理解告警含义并做出决策。我们称之为**告警增强（Alert Augmentation）**：

**原始告警**：
```
[ALARM] Station-05 水位超警戒 | 当前: 5.65m | 阈值: 5.50m | 时间: 14:32:15
```

**增强后告警**：
```
[告警增强] 5号监测站水位超警戒

■ 当前状态
  水位: 5.65m（超警戒0.15m），上升速率: 0.11 m/h（加速中）
  流量: 62.3 m³/s（超设计24.6%）

■ 原因分析
  上游连续降雨致来水量持续增加。过去3小时来水量增幅+35%。
  上游4号站2小时前已出现类似超警戒情况。

■ 规程匹配
  符合《胶东调水工程汛期调度规程》第4.3.2条"Ⅲ级应急响应"启动条件。
  应启动分洪预案，开启K45+800分洪闸。

■ 趋势预测
  若不采取措施，预计1.5小时后水位达到5.85m（接近安全包络上限5.90m）
  若开启分洪闸至50%开度，预计1小时后水位回落至5.50m以下

■ 建议操作
  [紧急] 开启K45+800分洪闸至50%开度
  [建议] 通知下游K80管理所准备接水

  置信度: 高（92%） | 物理AI引擎仿真已验证
  输入"执行"确认操作，或输入"详情"查看完整分析
```

增强后的告警不仅告知"发生了什么"，还告知"为什么发生"、"该怎么办"和"置信度如何"，大幅提升了调度员的SA水平和决策效率。

---

## 7.6 可解释性与推理透明

### 7.6.1 为什么可解释性是必需的

在水利调度中，可解释性（Explainability）不是"有则加分"的锦上添花，而是"缺之不可"的必要条件。原因有三：

**安全责任**：调度决策涉及公共安全，调度员需要理解AI建议的推理过程才能承担决策责任。如果调度员无法理解AI为什么这样建议，他既不敢接受（因为不知道是否正确），也无法解释自己的决策依据（事后追溯时需要说明决策逻辑）。

**信任建立**：如前文所述，过程信任是人机信任的重要组成部分。不透明的AI系统即使准确率很高，也难以获得调度员的持续信任——"它总是对的"不如"它对的原因我能理解"来得让人安心。

**错误检出**：即使AI系统整体准确率很高，在特定工况下也可能犯错。如果推理过程是透明的，调度员可以通过检查推理步骤来发现可能的错误——"这一步的假设不对"、"这条规程引用的是旧版本"。这是"人+AI > 人 或 AI"的关键机制。

### 7.6.2 多层次解释框架

不同调度员在不同场景下需要不同层次的解释。我们设计了三层解释框架：

**L1层——结论级解释（What）**

给出建议的核心结论和关键依据。这是默认的解释层级，所有建议都应至少包含这一层。

> 建议开启分洪闸至50%开度。主要依据：上游来水超设计30%，5号站水位持续上升，符合Ⅲ级应急响应条件。

**L2层——推理级解释（Why）**

展示关键的推理步骤，说明从数据到结论的逻辑链。当调度员需要理解"为什么是50%而不是其他值"时，可以请求这一层解释。

> 推理过程如下：
> 1. 数据输入：当前来水量65.3 m³/s，设计流量50 m³/s，超标30.6%
> 2. 规程匹配：查询《汛期调度规程》第4.3条，超标>25%应启动Ⅲ级响应
> 3. 方案搜索：Ⅲ级响应预案要求开启分洪闸，分洪能力需≥超标流量
> 4. 参数计算：超标流量=15.3 m³/s，分洪闸50%开度的分洪能力约12-15 m³/s
> 5. 仿真验证：物理AI引擎仿真确认50%开度方案可在1.5h内恢复安全水位
> 6. 安全校验：方案执行后各断面水位均在安全包络内

**L3层——证据级解释（Evidence）**

提供完整的数据来源、计算细节和参考依据。当调度员需要深度审查AI建议的可靠性或进行事后审计时使用。

> 证据明细：
> - 来水数据来源：SCADA站点YH-05，采样时间14:30:00 UTC+8，数据质量标记"优"
> - 规程版本：《胶东调水工程汛期调度规程》（2024年修订版），文件编号JD-OP-2024-003
> - 分洪闸额定能力：100%开度下最大分洪流量28 m³/s（依据闸门特性曲线JD-GC-045）
> - 仿真模型：MIKE11-ROM模型，校准精度NSE=0.95，最近校准时间2026-03-15
> - 仿真结果：[链接到完整仿真报告]

### 7.6.3 推理链可视化

对于复杂的多步推理，文字解释可能不够直观。系统应支持**推理链可视化（Reasoning Chain Visualization）**，将推理过程呈现为有向图：

```
[实时数据]  [气象预报]  [设备状态]
    ↓            ↓          ↓
    └─────→ [工况研判] ←────┘
                ↓
         [规程条款匹配]
                ↓
         [候选方案生成]
           ↙        ↘
    [方案A: 50%]  [方案B: 30%]
         ↓              ↓
    [仿真验证]    [仿真验证]
         ↓              ↓
    [安全✓ 效果✓]  [安全✓ 效果△]
         ↓
    [推荐方案A]
```

每个节点可以点击展开查看详细信息。这种可视化方式使调度员能够快速定位推理链中的关键节点，有针对性地审查自己关心的环节。

### 7.6.4 不确定性的诚实表达

可解释性的一个重要方面是诚实地表达不确定性。AI系统应该在以下情况下明确告知调度员其判断的局限：

**数据不确定性**："注意：K12站的流量传感器在过去1小时内出现3次数据跳变，该站数据可靠性标记为'待验证'。建议以相邻站点数据交叉校验。"

**模型不确定性**："当前工况（流量超设计40%）接近模型校准范围的边界。仿真结果的置信区间较正常工况有所扩大，建议采用偏保守的参数设置。"

**知识不确定性**："未在知识库中找到与当前工况完全匹配的历史案例。最相似的案例发生在2023年8月（相似度72%），但当时的设备配置与现在不同。"

**推理不确定性**："当前有两种可能的原因解释：(A) 上游来水增加导致水位上升（概率75%）；(B) 下游闸门堵塞导致壅水（概率25%）。建议先检查下游闸门状态以排除可能性B。"

这种诚实表达看似"示弱"，实际上是建立长期信任的关键——调度员知道"AI在有把握时会明确推荐，在不确定时会坦诚告知"，由此可以校准自己对AI建议的接受策略。

### 7.6.5 联合认知系统视角

上述可解释性设计可以从**联合认知系统（Joint Cognitive System, JCS）**的理论视角来理解。Hollnagel和Woods（2005）提出，人机系统不应被看作"人+机器"的简单叠加，而应被视为一个整体认知系统——人和机器共同完成感知、理解、决策和行动的认知功能。

在JCS视角下，可解释性不是"机器向人汇报"的单向信息传递，而是人机之间建立**共享心智模型（Shared Mental Model）**的过程。调度员需要理解AI的推理逻辑，AI也需要"理解"调度员的关注重点和决策偏好。只有双方在关键要素上建立了一致的理解，协同才能高效运作。

这一视角对系统设计的启示是：可解释性机制应该是**双向的**——不仅AI向调度员解释自己的推理，调度员也应该能够向AI表达自己的判断依据和偏好。例如：

> **调度员**：我不接受50%的方案。虽然仿真说安全，但这个闸门上周刚检修过，我不放心一次调这么大。
>
> **AI**：理解，您对K80闸门的设备状态有顾虑。调整为两步执行方案：先调至35%运行30分钟观察，确认设备正常后再调至50%。这样设备负荷变化更平缓。方案是否可接受？

AI通过理解调度员"拒绝"背后的原因（设备状态顾虑而非方案方向错误），生成了更合理的替代方案。这就是JCS中"共享心智模型"的实际体现。

---

## 7.7 信任校准机制

### 7.7.1 置信度展示的设计原则

置信度是信任校准的核心工具。但置信度的展示方式需要精心设计，以避免产生误导：

**语义化而非数字化**：对多数调度员而言，"置信度87%"和"置信度83%"的差异缺乏直觉意义。系统应将数字化置信度映射为语义化标签：

| 数值范围 | 语义标签 | 颜色编码 | 建议行为 |
|---------|---------|---------|---------|
| ≥ 90% | 高置信度 | 🟢 绿色 | 可以信赖，仍建议快速审核 |
| 70%-89% | 中高置信度 | 🟡 黄色 | 建议仔细审核推理过程 |
| 50%-69% | 中置信度 | 🟠 橙色 | 建议独立验证关键数据 |
| < 50% | 低置信度 | 🔴 红色 | 仅供参考，建议以人工判断为主 |

**分维度置信度**：总体置信度可能掩盖各环节的差异。系统应在需要时提供分维度置信度：

> 总体置信度：中高（82%）
> - 数据可靠性：高（95%）——SCADA数据质量良好
> - 规程匹配：高（90%）——明确匹配到具体条款
> - 方案有效性：中（65%）——仿真模型在此工况下的校准精度有限
> - 安全裕度：高（88%）——方案执行后仍有充足安全裕度

这种分维度展示帮助调度员精确定位需要额外关注的环节。

### 7.7.2 校准反馈闭环

信任校准不是单向的"AI展示置信度"，还需要调度员的反馈来校准AI自身的置信度估计：

**隐式反馈**：系统追踪调度员对AI建议的接受/修改/拒绝行为，分析模式：

- 高置信度建议被拒绝 → 可能AI的置信度估计偏高（过度自信）
- 低置信度建议被接受 → 可能AI的置信度估计偏低（过度保守）
- 建议被修改后接受 → 分析修改的部分，识别AI判断的薄弱环节

**显式反馈**：在非紧急时段，系统可以主动请求调度员的评价：

> 回顾：今天14:32的分洪方案建议（置信度85%），执行后5号站水位在预计时间内回落至安全范围。您对这次建议的评价：(A) 准确有帮助 (B) 方向正确但参数需调整 (C) 不太有帮助。

**校准报告**：系统定期生成置信度校准报告，统计不同置信度区间的实际准确率：

| 置信度区间 | 建议总数 | 接受数 | 修改后接受数 | 拒绝数 | 实际准确率 |
|-----------|---------|-------|------------|-------|-----------|
| 90-100% | 156 | 148 | 5 | 3 | 95% |
| 70-89% | 203 | 162 | 28 | 13 | 80% |
| 50-69% | 87 | 45 | 20 | 22 | 52% |
| <50% | 34 | 8 | 9 | 17 | 24% |

理想状态是"置信度90%的建议约90%是准确的"——即AI的自我评估与实际表现一致。如果发现系统性偏差（如高置信度的实际准确率明显低于标称值），则需要重新校准置信度模型。

### 7.7.3 信任修复策略

当AI系统犯错——特别是高置信度下的错误——调度员的信任会急剧下降。系统设计中应包含信任修复机制：

**即时响应**：当发现AI建议执行结果与预期不符时，系统应主动承认偏差并分析原因：

> 注意：14:32的分洪方案建议预计1.5小时内水位回落至警戒线以下，但实际水位在2.5小时后才回落。偏差原因分析：物理AI引擎的降雨-径流模型低估了上游持续降雨的累积效应。已记录此偏差用于模型校准改进。

**系统性改进**：将错误案例纳入评估数据集，改进模型训练和置信度估计。在后续类似工况中主动提示历史偏差记录。

**透明沟通**：在调度员培训和系统更新通报中，公开讨论AI系统的错误案例和改进措施。透明而非隐瞒是修复信任的最佳策略。

---

## 7.8 对话调度的交互界面设计

### 7.8.1 多模态交互

对话调度的界面不限于文本输入输出。考虑到调度场景的多样性，系统应支持多种交互模态：

**文本对话**：最基本的交互方式，适用于日常值班、详细查询和复杂分析。优势是表达精确、便于记录和审计。

**语音对话**：适用于双手被占用（如操作其他设备）或紧急场景。需要针对水利专业术语优化的语音识别（ASR）模型。注意：安全敏感的执行类操作即使通过语音发出，也应在屏幕上显示确认界面。

**图表交互**：在对话过程中嵌入交互式图表——水位过程线、闸门开度曲线、工况态势图等。调度员可以在图表上圈选关注区间、标注异常点，系统据此理解调度员的关注重点。

**SCADA联动**：对话界面与SCADA监控画面联动。当AI在对话中提到"K80闸门"时，SCADA画面自动定位到该闸门的监控画面；当调度员在SCADA画面上点击某个设备时，对话界面自动弹出该设备的状态摘要。

### 7.8.2 信息密度的分层呈现

调度对话的信息量可能很大，如果一次性呈现所有信息，调度员可能无法快速抓住重点。系统采用**渐进式信息展开**策略：

**第一层（摘要）**：用1-2句话给出核心结论和建议。这是调度员首先看到的内容。

> 5号站水位超警戒，建议开启分洪闸至50%。置信度：高。

**第二层（详情）**：展开数据依据和推理逻辑。调度员点击"详情"或说"为什么"时展开。

> 当前来水65.3 m³/s（超设计30.6%），符合Ⅲ级应急响应条件。仿真验证50%开度可在1.5h内恢复安全水位。

**第三层（完整分析）**：包含全部数据来源、计算过程、替代方案比较等。通常只在事后审计或深度分析时使用。

这种分层策略确保了紧急时刻调度员能在几秒钟内获取关键信息，同时保留了深入审查的可能性。

### 7.8.3 对话记录与审计

所有对话交互必须完整记录并支持事后审计。这不仅是工程管理的要求，也是法律合规的需要：

**记录内容**：每一轮对话的输入输出、AI的推理过程、置信度评分、调度员的决策（接受/修改/拒绝）、操作执行结果、时间戳。

**记录格式**：结构化的日志格式，支持按时间、按操作对象、按事件类型检索。

**保存期限**：参照水利工程调度记录的保存要求，至少保存5年。关键安全事件的记录永久保存。

**审计支持**：提供对话回放功能——输入某个时间点，可以完整重现当时的对话场景（包括当时的数据状态、AI的推理过程、调度员的决策）。这对于事后分析和责任追溯至关重要。

---

### 7.8.4 多调度员协同对话

实际水利调度往往不是单人操作，而是多个调度员、多个层级的协同。以胶东调水为例，一次汛期调度可能涉及省调度中心值班调度员、区域管理所调度员、防汛值班领导等多个角色。当认知AI引擎介入时，需要处理以下协同挑战：

**信息一致性**：多个调度员同时与AI系统交互时，各方获得的信息必须一致。系统在关键节点创建数据快照，避免因查询时差导致的信息不一致。

**权限层级**：不同角色的权限不同。省级调度员可以下达全渠段调度指令，区域管理所只能调整本区段设备。AI系统根据交互者的身份匹配相应的权限配置。

**决策冲突**：多个调度员可能对AI的同一建议有不同意见。系统遵循"上级优先、安全优先"的冲突解决原则。

我们设计了三种协同对话模式：

**广播式（Broadcast）**：AI的工况研判和告警增强同时推送给所有相关调度员，确保所有人"看到同一幅画面"。

**接力式（Relay）**：省级调度员请求AI生成全渠段的调度方案后，将方案中涉及各区段的子方案分发给相应的区域管理所。AI系统自动维护方案的分解和追踪关系。

**会议式（Conference）**：多个调度员同时加入一个共享对话会话，AI作为"会议助手"角色。示例：

> 省调度员A：建议全线预降水位0.5m。
>
> 区域调度员B：K80-K120段昨天刚完成预降，再降0.5m供水保证率不够。
>
> AI引擎：补充信息——K80-K120段当前水位已低于正常蓄水位0.3m。如果全线统一预降0.5m，该段可能无法满足15:00的灌区供水计划（缺口约2.1 m³/s）。建议差异化方案：K0-K80段预降0.5m，K80-K120段预降0.2m，K120以下预降0.4m。仿真结果显示各段均满足安全要求。
>
> 省调度员A：同意差异化方案。B站那边同意吗？
>
> 区域调度员B：0.2m可以接受，同意。

在会议模式中，AI的角色是补充信息、提供量化分析和促进共识达成，而非替任何一方做决策。

协同状态同步的关键机制包括：操作锁定（防止对同一设备的冲突操作）、变更通知（状态变化自动通知所有参与者）和版本快照（关键节点的数据一致性保障）。

### 7.8.5 网络异常与降级处理

对话调度系统依赖多层网络连接（对话终端↔认知AI引擎↔物理AI引擎↔SCADA系统），任何环节的中断都可能影响功能。系统必须具备完善的降级处理能力：

**对话终端与认知AI引擎断开**：对话界面自动切换到"离线模式"，显示最近一次的工况摘要和预存的应急操作指南。调度员通过SCADA系统进行传统人工调度。

**认知AI引擎与物理AI引擎断开**：AI可以进行知识查询和规程匹配，但无法调用仿真验证。AI明确告知"以下建议未经仿真确认，请谨慎评估"，置信度自动下调一级。

**SCADA数据中断**：AI使用最后已知的SCADA数据，并标注数据时效——"以下分析基于XX:XX的数据，当前SCADA数据不可用"。对于时效性要求高的场景，明确建议通过其他渠道获取实时数据。

网络恢复后的状态恢复包括三个步骤：数据对齐（获取断开期间的SCADA数据，更新工况研判），对话上下文恢复（从中断处继续交互），操作一致性检查（对比手动操作与AI之前建议的差异）。

降级处理的核心原则是**安全优先、功能渐退、透明告知**——宁可功能减少也不能给出不可靠的建议，并且让调度员随时清楚当前系统处于什么状态。

---

## 7.9 调度员培训与适应

### 7.9.1 培训目标

对话调度系统的引入不仅是技术变革，也是调度员工作方式和思维方式的变革。培训方案的目标是：

**能力目标**：调度员能够熟练使用对话调度系统，包括自然语言交互、意图表达、信息层级导航和多模态操作。

**认知目标**：调度员理解AI系统的能力边界——知道它擅长什么、不擅长什么、什么时候该信任它、什么时候该质疑它。

**协作目标**：调度员能够与AI系统形成高效的协作模式——既不过度依赖AI也不忽视AI，在AI与自身判断不一致时能够做出合理的决策。

### 7.9.2 培训内容体系

培训体系分为四个模块，总学时约40小时：

**模块一：系统认知（8学时）**

- 认知AI引擎的功能与架构概述
- AI系统的能力边界与局限性
- 置信度和解释性信息的解读方法
- WNAL等级与决策权限分配
- 案例学习：AI曾经犯过的典型错误

这个模块的目标不是让调度员成为AI专家，而是建立对AI能力的现实认知——既不高估也不低估。

**模块二：交互技能（12学时）**

- 自然语言表达的最佳实践（如何清晰表达查询需求、如何指定操作对象和参数）
- 多轮对话策略（如何追问、如何切换话题、如何回溯）
- 多模态交互操作（语音、图表交互、SCADA联动）
- 紧急场景下的快速交互技巧
- 实操练习：10个典型场景的模拟对话

**模块三：协同决策（12学时）**

- 人机协同决策的心理学基础
- 自动化偏信的识别与克服
- AI建议的审核方法（如何快速验证AI推理的合理性）
- 人工与AI判断不一致时的处理策略
- 角色扮演练习：调度员与AI的协同决策模拟

**模块四：应急能力（8学时）**

- AI系统故障时的人工接管流程
- 降级运行模式下的调度操作
- 系统恢复后的信息对接
- 年度应急演练方案

### 7.9.3 循序渐进的上线策略

对话调度系统的引入不宜一步到位，而应采取**渐进式上线**策略：

**第一阶段：影子模式（Shadow Mode）**（1-2个月）

AI系统在后台运行，生成建议但不呈现给调度员。系统团队对比AI建议与调度员的实际决策，评估AI的准确率和实用性。这个阶段的目标是验证AI系统的工程适用性。

**第二阶段：建议模式（Advisory Mode）**（2-3个月）

AI建议呈现在调度员的辅助屏幕上，作为参考信息。调度员可以选择参考或忽略。系统收集调度员的使用反馈和接受率数据。这个阶段的目标是让调度员逐步建立对AI的认知和初步信任。

**第三阶段：协作模式（Collaborative Mode）**（持续）

AI系统与调度员进入正式的协同工作模式——对话交互、方案推荐、主动推送等功能全面启用。系统持续优化并根据反馈调整。这个阶段的目标是实现人+AI的协同增效。

**第四阶段：深度自主模式（Deep Autonomy Mode）**（条件成熟时）

在充分验证和积累信任的基础上，逐步提升WNAL等级——部分常规操作允许AI自动执行（调度员有否决权）。这个阶段需要监管部门的认可和制度层面的支持。

### 7.9.4 持续评估与能力保持

培训不是一次性的，而是持续的过程。系统应支持：

**定期能力评估**：每季度组织一次调度员与AI系统协同能力的评估，包括标准化的场景测试和实际工作表现分析。

**人工技能保持**：定期安排"AI断开"演练——在安全可控的条件下，关闭AI辅助，让调度员完全依靠人工进行调度操作。这可以防止技能退化，确保调度员在AI故障时能够有效接管。

**经验分享**：建立调度员之间的经验分享机制——"我发现这样提问AI回答更准确"、"遇到这种工况时AI建议不太靠谱，我是这样处理的"。这种同伴学习比系统化培训更能帮助调度员建立恰当的信任水平。

---

## 7.10 案例研究：胶东调水对话调度系统

### 7.10.1 工程背景

胶东调水工程是山东省重大水利基础设施，干渠全长约240km，设计流量50 m³/s，沿线设有多座节制闸、分洪闸和分水口。工程的调度管理由省级调度中心统一指挥，沿线设若干区域管理所。

传统调度模式面临的主要挑战包括：长距离调水的水力传播延时大（数小时至十余小时），沿线用水户需求多样且动态变化，汛期来水不确定性高，值班调度员的认知负荷在复杂工况下极高。

2025年启动的智能化升级项目引入了基于CHS框架的对话调度系统，包含物理AI引擎（基于MIKE11降阶模型的MPC优化器）和认知AI引擎（基于瀚铎水网大模型+RAG的对话系统）。

### 7.10.2 系统架构

胶东调水对话调度系统的架构如下：

```
┌─────────────────────────────────────────────┐
│              调度员对话界面                    │
│  文本对话 │ 语音输入 │ 图表联动 │ SCADA联动   │
├─────────────────────────────────────────────┤
│              认知AI引擎                      │
│  ┌─────────┐  ┌──────────┐  ┌─────────┐   │
│  │ 瀚铎模型 │  │ RAG检索  │  │ 对话管理 │   │
│  │ (14B参数)│  │ (规程+案例)│  │ (状态跟踪)│   │
│  └────┬────┘  └────┬─────┘  └────┬────┘   │
│       └───────────┼──────────────┘         │
│                   ↓                         │
│         任务编排 + 安全审核                    │
├──────────────┬──────────────────────────────┤
│  物理AI引擎  │         HydroOS              │
│  ┌─────────┐ │  ┌──────────┐  ┌─────────┐ │
│  │ROM+MPC  │ │  │ SCADA数据│  │ 设备控制 │ │
│  │优化计算  │ │  │  采集层  │  │  接口层  │ │
│  └─────────┘ │  └──────────┘  └─────────┘ │
└──────────────┴──────────────────────────────┘
```

核心配置参数：

- 瀚铎模型：14B参数版本（Qwen-2.5-14B基座，CHS领域CPT+SFT+DPO）
- RAG知识库：《胶东调水工程调度规程》（含汛期/非汛期/应急三套规程）、历史调度记录（2015-2025年，约12万条）、设备手册和维护记录
- 对话管理：基于DST的多轮对话引擎，支持话题栈管理
- 物理AI引擎接口：REST API调用MIKE11降阶模型，P95响应时间 < 3秒
- WNAL配置：L2（条件自主），闸门调整幅度 ≤ 10%可自动执行

### 7.10.3 权限配置

胶东调水系统的权限策略根据工程实际进行了定制化配置：

**正常运行期（非汛期）**

- 闸门微调（≤5%开度变化）：AI自动执行，事后通知调度员
- 闸门中幅调整（5%-20%）：AI推荐+调度员确认
- 闸门大幅调整（>20%）：AI推荐+调度员确认+值班长复核
- 分水口开关：AI推荐+调度员确认（涉及用水户利益）

**汛期**

- 所有闸门操作：AI推荐+调度员确认（权限自动收紧）
- 分洪操作：AI推荐+调度员确认+值班长复核+汛期值班领导审批
- 应急工况（水位超安全包络）：AI降级为信息提供者角色，人工主导决策

### 7.10.4 典型对话场景复现

以下是系统上线后的一次实际调度对话（非汛期常规调度，已脱敏）：

> **调度员**：今天下午桩号K60-K120段的分水口供水计划是什么？
>
> **AI**：今日下午（14:00-18:00）K60-K120段共有3个分水口计划供水：
> - K72+300向某市供水，计划流量5.2 m³/s，14:00-17:00
> - K95+000向某灌区补水，计划流量3.8 m³/s，15:00-18:00
> - K108+500向某水库补库，计划流量2.0 m³/s，14:00-16:00
> 合计最大取水流量11.0 m³/s（15:00-16:00时段），占当前干渠流量的25.6%。
>
> **调度员**：如果K72的供水提前到13:00开始，对下游水位有影响吗？
>
> **AI**：已调用物理AI引擎进行仿真计算。如果K72+300供水提前1小时至13:00开始：
> - K80+000段水位将在13:40左右下降约0.08m（因上游取水减少了过境流量）
> - K95+000段水位将在14:10左右下降约0.05m
> - 影响幅度较小，所有断面水位均在安全包络内
>
> 建议：可以提前供水。如需保持下游水位稳定，可以将上游K45节制闸开度增加2%作为补偿。是否执行？
>
> **调度员**：不用增加K45开度了，0.08m的波动可以接受。确认K72提前到13:00。
>
> **AI**：确认。已将K72+300分水口开启时间调整为13:00，其他参数不变。将在12:50自动提醒您确认开闸操作。

这段对话展示了对话调度的核心价值：调度员用自然语言提出需求和假设（"如果提前到13:00开始"），AI系统自动调用物理AI引擎进行仿真计算，并以调度员容易理解的方式呈现结果和建议。整个过程不到2分钟，而传统模式下可能需要10-15分钟的手动计算和多次电话沟通。

### 7.10.5 效果评估

系统上线运行6个月后（2025年7月-2026年1月）的效果评估数据：

**调度效率**

| 指标 | 传统模式 | 对话调度模式 | 提升 |
|------|---------|-------------|------|
| 单次调度决策平均耗时 | 12.5分钟 | 4.2分钟 | -66% |
| 值班期间日均查阅规程次数 | 8.3次 | 1.2次（由AI代劳） | -86% |
| 复杂工况的方案准备时间 | 35分钟 | 10分钟 | -71% |

**决策质量**

| 指标 | 传统模式 | 对话调度模式 |
|------|---------|-------------|
| AI建议采纳率 | — | 83.6% |
| 采纳后方案成功率 | — | 96.2% |
| 调度偏差（实际vs目标水位） | ±0.12m | ±0.07m |
| 紧急工况响应时间 | 8.5分钟 | 3.8分钟 |

**调度员反馈**

通过匿名问卷（18名调度员参与，回收率100%），主要发现：

- 88.9%的调度员认为对话调度系统"有帮助"或"非常有帮助"
- 72.2%的调度员表示"信任度中高"，22.2%表示"信任度高"，5.6%表示"信任度一般"
- 最受欢迎的功能：告警增强（94.4%）、规程自动匹配（88.9%）、仿真联动（83.3%）
- 主要改进需求：语音识别的专业术语准确率（66.7%）、复杂工况下的建议可靠性（55.6%）

### 7.10.6 经验教训

系统实施过程中的关键经验教训：

**教训一：渐进式上线是必要的**。最初尝试直接上线完整功能时，部分资深调度员产生抵触情绪——"机器能比我干了三十年的人更懂调水？"通过先在影子模式下运行，用数据证明AI建议与资深调度员的决策吻合度超过85%，才逐步赢得信任。

**教训二：错误处理比正确处理更重要**。系统上线初期的一次高置信度错误建议（因模型未考虑临时检修导致的断面变化）严重打击了调度员信任。之后专门设计了"错误后修复"协议——及时承认、分析原因、改进措施、透明通报——才逐步恢复信任。

**教训三：调度员参与设计**。最初由技术团队独立设计的对话界面，调度员反馈"太像聊天机器人，不像调度工具"。邀请一线调度员参与界面重新设计后，增加了SCADA联动、快捷操作按钮和工况态势面板，实用性大幅提升。

**教训四：人工技能保持不可忽视**。上线3个月后的"AI断开"演练发现，部分年轻调度员在无AI辅助时的决策速度和准确性明显下降，表明技能退化已经开始。此后将"AI断开"演练纳入月度常规训练。

---

## 本章小结

本章系统讨论了人机协同决策与对话调度的理论基础、设计方法和工程实践，主要内容包括：

1. **调度模式范式转变**：从手动调度到数字化调度再到对话调度，核心变化是信息流向从"人找信息"转变为"AI主动推送决策相关信息"。对话调度是增强而非取代调度员。

2. **理论基础**：自动化层级（LOA）模型为人机分工提供了分级框架；情境感知（SA）理论揭示了调度员的认知需求和AI可以支持的层次；人机信任动态模型说明了信任的三维基础（性能、过程、目的）和动态演化规律。特别强调了自动化偏信、惊吓和技能退化等认知偏差的风险。

3. **决策权限分配**：基于WNAL等级的四维权限矩阵，结合工况-置信度-权限三级联动机制，实现了安全与效率的平衡。关键决策的"四眼原则"确保了安全底线。声明式权限策略文件使配置透明可审。

4. **对话交互设计**：针对水利调度的实时性、准确性和专业性特点，设计了完整的意图分类体系、多轮对话状态管理机制、澄清策略和对话策略引擎。话题栈和共指消解确保了复杂多轮对话的连贯性。

5. **主动推送与告警增强**：从四级优先级分级到智能推送时机选择，再到将简单阈值告警增强为包含原因分析、规程匹配和趋势预测的综合告警。

6. **可解释性与信任校准**：三层解释框架（结论→推理→证据）、推理链可视化、不确定性诚实表达、分维度置信度展示和校准反馈闭环，共同服务于建立恰当的人机信任。

7. **调度员培训与渐进上线**：四模块培训体系、四阶段渐进上线策略和持续的能力保持机制，确保技术变革的平稳过渡。

8. **工程实践**：胶东调水对话调度系统的案例展示了上述设计在实际工程中的应用效果——调度效率提升66%，决策偏差降低42%，调度员满意度89%。同时，渐进式上线、错误处理、用户参与设计和技能保持等经验教训为后续工程提供了宝贵参考。

---

## 习题

### 基础题

**7-1.** 解释Sheridan-Verplank自动化层级（LOA）模型，并说明WNAL L2等级对应LOA的哪个层级。为什么当前水利调度普遍采用L2-L3而非更高的自动化等级？

**7-2.** 解释人机信任的三维基础（性能信任、过程信任、目的信任），并各举一个水利调度中的例子说明这三种信任如何建立或破坏。

**7-3.** 什么是"自动化偏信"（Automation Complacency）？在水利调度中，自动化偏信可能导致哪些具体风险？系统设计中可以采取哪些措施来缓解这一问题？

### 应用题

**7-4.** 为以下调度场景设计完整的对话流程（至少6轮对话），包括意图识别、澄清策略和权限检查：

> 场景：汛期，上游预报将有大到暴雨，调度员需要制定预降水位方案。当前干渠水位处于正常高水位运行状态。

**7-5.** 设计一个告警增强模板，将以下原始SCADA告警增强为认知AI引擎的增强告警：

> 原始告警：[ALARM] Pump-03 电流过高 | 当前: 285A | 阈值: 250A | 时间: 03:15:22

要求包含原因分析、规程匹配、影响评估和建议操作。

### 思考题

**7-6.** "AI系统的置信度展示是一把双刃剑"——高置信度可能导致调度员放松审核，而频繁的低置信度可能导致调度员不再关注AI建议。如何设计置信度展示机制，使其既能提供有用信息又不产生上述负面效应？考虑展示方式、展示时机和调度员差异化需求。

**7-7.** 本章的胶东调水案例显示，系统上线3个月后年轻调度员出现了技能退化迹象。如果你是系统设计者，你会采取哪些长期措施来平衡"AI辅助提升效率"与"人工技能持续保持"这对矛盾？是否存在一种设计，能够在提供AI辅助的同时反而增强调度员的自身能力？

---

## 拓展阅读

1. **Parasuraman, R., Sheridan, T.B., and Wickens, C.D. (2000).** "A Model for Types and Levels of Human Interaction with Automation." *IEEE Transactions on Systems, Man, and Cybernetics—Part A*, 30(3), 286-297. — 自动化层级的经典论文，提出了四维LOA框架。

2. **Lee, J.D. and See, K.A. (2004).** "Trust in Automation: Designing for Appropriate Reliance." *Human Factors*, 46(1), 50-80. — 人机信任领域最重要的综述之一，提出了性能-过程-目的信任框架。

3. **Endsley, M.R. (1995).** "Toward a Theory of Situation Awareness in Dynamic Systems." *Human Factors*, 37(1), 32-64. — 情境感知理论的奠基性论文，三层SA模型被广泛应用于人机系统设计。

4. **Amershi, S. et al. (2019).** "Guidelines for Human-AI Interaction." *Proceedings of CHI 2019*, ACM. — 微软研究院提出的人机AI交互设计指南，18条设计原则对于对话调度系统设计具有重要参考价值。

5. **Lei, X. et al. (2025b).** "Architecture of Autonomous Intelligent Water Networks." *南水北调与水利科技*, DOI: 10.13476/j.cnki.nsbdqk.2025.0079. — CHS框架中WNAL分级体系和双引擎架构的正式论述。

---

> **下一章预告**：第八章将探讨认知智能与物理AI的融合——如何实现认知AI引擎与物理AI引擎的深度协同，构建"知行合一"的水网智能控制系统。我们将讨论双引擎耦合架构、物理信息增强的LLM推理、以及认知AI驱动的自适应控制策略。
